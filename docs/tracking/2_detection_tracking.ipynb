{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c64a6421-cc17-49ff-90f6-4b475ca32ec1",
   "metadata": {},
   "source": [
    "# tracking the birds\n",
    "currently only compatible with roboflow's csv output format (working on it) \n",
    "\n",
    "bounding boxes can be downloaded from serverless roboflow API, or run locally using:\n",
    "#### Import the InferencePipeline object\n",
    "from inference import InferencePipeline\n",
    "import cv2\n",
    "\n",
    "def my_sink(result, video_frame):\n",
    "    if result.get(\"output_image\"): # Display an image from the workflow response\n",
    "        cv2.imshow(\"Workflow Image\", result[\"output_image\"].numpy_image)\n",
    "        cv2.waitKey(1)\n",
    "    print(result) # do something with the predictions of each frame\n",
    "\n",
    "\n",
    "#### initialize a pipeline object\n",
    "pipeline = InferencePipeline.init_with_workflow(\n",
    "    api_key=\"uRlfoIT0LJUs3mEMvNXV\",\n",
    "    workspace_name=\"basis-internship\",\n",
    "    workflow_id=\"detect-count-and-visualize-4\",\n",
    "    video_reference=0, # Path to video, device id (int, usually 0 for built in webcams), or RTSP stream url\n",
    "    max_fps=30,\n",
    "    on_prediction=my_sink\n",
    ")\n",
    "pipeline.start() #start the pipeline\n",
    "pipeline.join() #wait for the pipeline thread to finish\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dbd4cb-2b4b-41a5-85fd-adb6ed16e0f3",
   "metadata": {},
   "source": [
    "### set up the environment\n",
    "istall and import any necessary packages \n",
    "move to GPU if available (i.e. on runpod) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a78e941-e4cd-415c-9a9a-7393d71864d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Environment Setup\n",
    "# ------------------------------\n",
    "# Install necessary packages\n",
    "# !pip install tqdm opencv-python-headless ultralytics matplotlib ipywidgets supervision rfdetr\n",
    "# !pip install git+https://github.com/kadirnar/bytetrack-pip.git\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import yaml\n",
    "import random, shutil\n",
    "import tempfile\n",
    "\n",
    "from bytetracker.byte_tracker import BYTETracker\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from ipywidgets import interact, IntSlider\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "# Check GPU\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30103c2c-8cee-4e68-887b-f996958604ba",
   "metadata": {},
   "source": [
    "### visualize the model output\n",
    "before tracking, check the bounding boxes and object **detections** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf222fc-e76a-4115-82c3-639d34ff219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by manually checking the boudning boxes from running the object detection\n",
    "\n",
    "def visualize_detections_from_csv(csv_path: Path, frame_dir: Path, output_video_path: Path, fps: int =30):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df[\"parsed_predictions\"] = df[\"predictions\"].apply(json.loads)\n",
    "\n",
    "    frame_paths = sorted(frame_dir.glob(\"15_*.jpg\"))\n",
    "    if not frame_paths:\n",
    "        print(f\"⚠️ No frames found in {frame_dir}\")\n",
    "        return\n",
    "\n",
    "    sample_frame = cv2.imread(str(frame_paths[0]))\n",
    "    h, w = sample_frame.shape[:2]\n",
    "\n",
    "    writer = cv2.VideoWriter(str(output_video_path), cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "    for idx, frame_path in enumerate(frame_paths):\n",
    "        frame = cv2.imread(str(frame_path))\n",
    "        if frame is None or idx >= len(df):\n",
    "            continue\n",
    "\n",
    "        preds = df.iloc[idx][\"parsed_predictions\"][\"predictions\"]\n",
    "        for obj in preds:\n",
    "            x, y, w_box, h_box = obj[\"x\"], obj[\"y\"], obj[\"width\"], obj[\"height\"]\n",
    "            conf = obj.get(\"confidence\", None)\n",
    "\n",
    "            x1 = int(x - w_box / 2)\n",
    "            y1 = int(y - h_box / 2)\n",
    "            x2 = int(x + w_box / 2)\n",
    "            y2 = int(y + h_box / 2)\n",
    "\n",
    "            color = (0, 255, 0)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            label = f\"{obj.get('class', 'bird')}: {conf:.2f}\" if conf is not None else \"bird\"\n",
    "            cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        writer.write(frame)\n",
    "\n",
    "    writer.release()\n",
    "    print(f\"✅ Annotated video saved to: {output_video_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f740242-a63f-4799-97e6-44b120637d72",
   "metadata": {},
   "source": [
    "based on the folder structure, there should be a 'extracted_frames' folder in each of the thermal subfolders. This is what we will be feeding to the tracker and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af129dd-9717-4581-bc14-485ca0c9e52d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Desktop/labeling_data/data_structure/2024-05-18-session_0004/thermal_1/thermal_7.0_21.0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m frame_dir = Path(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDesktop/labeling_data/data_structure/extracted_frames/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthermal\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m output_video_path = Path(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDesktop/labeling_data/data_structure/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthermal\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/detections.mp4\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m visualize_detections_from_csv(csv_file, frame_dir, output_video_path)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mvisualize_detections_from_csv\u001b[39m\u001b[34m(csv_path, frame_dir, output_video_path, fps)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvisualize_detections_from_csv\u001b[39m(csv_path: Path, frame_dir: Path, output_video_path: Path, fps: \u001b[38;5;28mint\u001b[39m =\u001b[32m30\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     df = pd.read_csv(csv_path)\n\u001b[32m      5\u001b[39m     df[\u001b[33m\"\u001b[39m\u001b[33mparsed_predictions\u001b[39m\u001b[33m\"\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33mpredictions\u001b[39m\u001b[33m\"\u001b[39m].apply(json.loads)\n\u001b[32m      7\u001b[39m     frame_paths = \u001b[38;5;28msorted\u001b[39m(frame_dir.glob(\u001b[33m\"\u001b[39m\u001b[33m15_*.jpg\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/yolo/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/yolo/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = TextFileReader(filepath_or_buffer, **kwds)\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/yolo/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28mself\u001b[39m._make_engine(f, \u001b[38;5;28mself\u001b[39m.engine)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/yolo/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = get_handle(\n\u001b[32m   1881\u001b[39m     f,\n\u001b[32m   1882\u001b[39m     mode,\n\u001b[32m   1883\u001b[39m     encoding=\u001b[38;5;28mself\u001b[39m.options.get(\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m   1884\u001b[39m     compression=\u001b[38;5;28mself\u001b[39m.options.get(\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m   1885\u001b[39m     memory_map=\u001b[38;5;28mself\u001b[39m.options.get(\u001b[33m\"\u001b[39m\u001b[33mmemory_map\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[32m   1886\u001b[39m     is_text=is_text,\n\u001b[32m   1887\u001b[39m     errors=\u001b[38;5;28mself\u001b[39m.options.get(\u001b[33m\"\u001b[39m\u001b[33mencoding_errors\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1888\u001b[39m     storage_options=\u001b[38;5;28mself\u001b[39m.options.get(\u001b[33m\"\u001b[39m\u001b[33mstorage_options\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m   1889\u001b[39m )\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/yolo/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m    876\u001b[39m             encoding=ioargs.encoding,\n\u001b[32m    877\u001b[39m             errors=errors,\n\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Desktop/labeling_data/data_structure/2024-05-18-session_0004/thermal_1/thermal_7.0_21.0.csv'"
     ]
    }
   ],
   "source": [
    "# run it! \n",
    "\n",
    "TARGET_ROOT_DIR = Path(\"Desktop/labeling_data/data_structure\")\n",
    "SESSION_ROOT_DIR = '2024_05_18-session_0004'\n",
    "thermal = \"thermal_1\"\n",
    "\n",
    "csv_file = Path(f\"{TARGET_ROOT_DIR}/{SESSION_ROOT_DIR}/{thermal}/thermal_7.0_21.0.csv\")\n",
    "frame_dir = Path(f\"{TARGET_ROOT_DIR}/extracted_frames/{SESSION_ROOT_DIR}_{thermal}\")\n",
    "output_video_path = Path(f\"{TARGET_ROOT_DIR}/{SESSION_ROOT_DIR}/{thermal}/detections.mp4\")\n",
    "\n",
    "visualize_detections_from_csv(csv_file, frame_dir, output_video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cdd7bb-55ed-4905-ac8d-b19a5e291e56",
   "metadata": {},
   "source": [
    "## tracking! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38735918-a224-4b13-ada8-3c65d283c9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the bytetracker tracker! \n",
    "\n",
    "def track_objects(csv_path: Path) -> dict:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df[\"parsed_predictions\"] = df[\"predictions\"].apply(json.loads)\n",
    "    all_frames = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        detections = []\n",
    "        for obj in row[\"parsed_predictions\"][\"predictions\"]:\n",
    "            x, y, w, h, conf = obj[\"x\"], obj[\"y\"], obj[\"width\"], obj[\"height\"], obj[\"confidence\"]\n",
    "            x1, y1 = x - w / 2, y - h / 2\n",
    "            x2, y2 = x + w / 2, y + h / 2\n",
    "            detections.append([x1, y1, x2, y2, conf])\n",
    "        all_frames.append(detections)\n",
    "\n",
    "    tracker = BYTETracker()\n",
    "    track_history = {}\n",
    "\n",
    "    for frame_idx, detections in enumerate(all_frames):\n",
    "        if not detections:\n",
    "            continue\n",
    "        dets_np = np.array(detections)\n",
    "        if dets_np.ndim != 2 or dets_np.shape[1] < 5:\n",
    "            continue\n",
    "        class_ids = np.zeros((dets_np.shape[0], 1))\n",
    "        formatted_dets = np.hstack((dets_np[:, :5], class_ids))\n",
    "        tracked = tracker.update(formatted_dets)\n",
    "\n",
    "        for det in tracked:\n",
    "            x1, y1, x2, y2, track_id, _ = det[:6]\n",
    "            cx, cy = int((x1 + x2) / 2), int((y1 + y2) / 2)\n",
    "            track_history.setdefault(track_id, []).append((frame_idx, (cx, cy)))\n",
    "\n",
    "    return track_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1548e1f-fe45-46ce-9b1e-bfc5d1b2b441",
   "metadata": {},
   "source": [
    "### actually running the tracking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd4cc5c-2308-4969-a78a-428629fbf360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected session: 2024_05_18-session_0002\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Root structure\n",
    "sessions = [p for p in TARGET_ROOT_DIR.iterdir() if p.is_dir() and p.name.startswith(\"2024_05_18-session_\")]\n",
    "\n",
    "results_dir = Path(TARGET_ROOT_DIR/\"tracking_results\")\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "session_path = sessions[0]\n",
    "print(\"Selected session:\", session_path.name)\n",
    "\n",
    "for thermal_sub in [\"thermal_1\", \"thermal_2\"]:\n",
    "    subfolder_path = Path(session_path / thermal_sub)\n",
    "    if not subfolder_path.exists():\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        csv_file = next(subfolder_path.glob(\"time_cropped-*.csv\"))\n",
    "    except StopIteration:\n",
    "        print(f\"⚠️ No CSV found in {subfolder_path}\")\n",
    "        continue\n",
    "\n",
    "    frame_subdir_name = f\"{session_path.name}_{thermal_sub}\"\n",
    "    frame_dir = TARGET_ROOT_DIR / \"extracted_frames\" / frame_subdir_name\n",
    "\n",
    "    if not frame_dir.exists():\n",
    "        print(f\"⚠️ Missing frames at: {frame_dir}\")\n",
    "        continue\n",
    "\n",
    "    # Get tracking history\n",
    "    track_history = track_objects(csv_file)\n",
    "        \n",
    "    # Save each track's timeline as a CSV in the same folder as the input CSV\n",
    "    output_csv = subfolder_path / f\"{thermal_sub}_tracks.csv\"\n",
    "    \n",
    "    with open(output_csv, \"w\") as f:\n",
    "        f.write(\"track_id,frame,x,y\\n\")\n",
    "        for tid, points in track_history.items():\n",
    "            for frame_idx, (x, y) in points:\n",
    "                f.write(f\"{tid},{frame_idx},{x},{y}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a44022-8398-493a-b28e-f402cd4a4c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization! \n",
    "\n",
    "def overlay_tracks_on_video(csv_path: Path, frame_dir: Path, output_video: Path, fps: int = 15):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df[\"track_id\"] = df[\"track_id\"].astype(int)\n",
    "\n",
    "    track_colors = {}\n",
    "\n",
    "    frame_paths = sorted(frame_dir.glob(\"15_*.jpg\"))\n",
    "    if not frame_paths:\n",
    "        raise FileNotFoundError(f\"No frames found in {frame_dir}\")\n",
    "\n",
    "    # Get frame size\n",
    "    sample_frame = cv2.imread(str(frame_paths[0]))\n",
    "    h, w = sample_frame.shape[:2]\n",
    "    writer = cv2.VideoWriter(str(output_video), cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
    "\n",
    "    for frame_path in frame_paths:\n",
    "        frame_idx = int(frame_path.stem.split(\"_\")[-1])\n",
    "        frame = cv2.imread(str(frame_path))\n",
    "\n",
    "        frame_tracks = df[df[\"frame\"] == frame_idx]\n",
    "        for _, row in frame_tracks.iterrows():\n",
    "            tid, x, y = int(row[\"track_id\"]), int(row[\"x\"]), int(row[\"y\"])\n",
    "            color = track_colors.setdefault(tid, tuple((np.random.rand(3) * 255).astype(int)))\n",
    "\n",
    "            #cv2.circle(frame, (x, y), 5, color, -1)\n",
    "            cv2.circle(frame, (x, y), 5, (255, 255, 0), -1)\n",
    "            #cv2.putText(frame, f\"ID {tid}\", (x + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "        writer.write(frame)\n",
    "\n",
    "    writer.release()\n",
    "    print(f\"✅ Saved annotated video to: {output_video}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a103c2a-9e44-4ea4-842f-b2a94395b6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved annotated video to: Desktop/labeling_data/data_structure/2024_05_18-session_0002/thermal_1/tracking_overlay.mp4\n"
     ]
    }
   ],
   "source": [
    "session = \"2024_05_18-session_0002\"\n",
    "thermal = \"thermal_1\"\n",
    "\n",
    "csv_file = Path(f\"Desktop/labeling_data/data_structure/{session}/{thermal}/{thermal}_tracks.csv\")\n",
    "frames = Path(f\"Desktop/labeling_data/data_structure/extracted_frames/{session}_{thermal}\")\n",
    "output_video_path = Path(f\"Desktop/labeling_data/data_structure/{session}/{thermal}/tracking_overlay.mp4\")\n",
    "\n",
    "\n",
    "# run it! \n",
    "\n",
    "TARGET_ROOT_DIR = Path(\"Desktop/labeling_data/data_structure\")\n",
    "SESSION_ROOT_DIR = '2024_05_18-session_0004'\n",
    "thermal = \"thermal_1\"\n",
    "\n",
    "csv_file = Path(f\"Desktop/labeling_data/data_structure/{SESSION_ROOT_DIR}/{thermal}/thermal_7.0_21.0.csv\")\n",
    "frame_dir = Path(f\"Desktop/labeling_data/data_structure/extracted_frames/{SESSION_ROOT_DIR}_{thermal}\")\n",
    "output_video_path = Path(f\"Desktop/labeling_data/data_structure/{SESSION_ROOT_DIR}/{thermal}/detections.mp4\")\n",
    "\n",
    "\n",
    "overlay_tracks_on_video(csv_file, frames, output_video_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
