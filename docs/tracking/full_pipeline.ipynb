{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a20766",
   "metadata": {},
   "source": [
    "# Full Tracker: Download, Process, and Upload Data\n",
    "This notebook demonstrates the full pipeline for handling raw data:\n",
    "1. Download data from a cloud bucket.\n",
    "2. Process the data (e.g., align videos, run detection, and tracking).\n",
    "3. Upload the processed data back to the cloud bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00d07572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Dict, Tuple\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import Custom Scripts\n",
    "from collab_env.tracking.thermal_processing import process_directory, validate_session_structure\n",
    "from collab_env.tracking.align_videos_manually import align_videos, step1_crop_and_prepare, step2_spatial_alignment, save_warped_video\n",
    "from collab_env.tracking.local_model_tracking import run_tracking, overlay_tracks_on_video, visualize_detections_from_video\n",
    "import subprocess\n",
    "\n",
    "from collab_env.data.file_utils import expand_path, get_project_root\n",
    "from collab_env.data.gcs_utils import GCSClient\n",
    "\n",
    "\n",
    "# Reload helper for dev work\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d4395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-25 14:20:00.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcollab_env.data.gcs_utils\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mUsing credentials from /Users/dima/git/collab-environment/config-local/collab-data-463313-c340ad86b28e.json\u001b[0m\n",
      "\u001b[32m2025-07-25 14:20:00.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcollab_env.data.gcs_utils\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mUsing project collab-data-463313\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Setup Configuration\n",
    "load_dotenv()\n",
    "data_key = expand_path(os.environ.get(\"COLLAB_DATA_KEY\", \"\"), get_project_root())\n",
    "PROJECT_ID = \"collab-data-463313\"\n",
    "\n",
    "CREDENTIALS_PATH = expand_path(data_key.as_posix(), get_project_root())\n",
    "\n",
    "# Connect to Google Cloud Storage\n",
    "gcs_client = GCSClient(\n",
    "    project_id=PROJECT_ID,\n",
    "    credentials_path=CREDENTIALS_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94fb308b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available buckets: ['fieldwork_curated', 'fieldwork_processed']\n"
     ]
    }
   ],
   "source": [
    "# Verify connection\n",
    "print(\"Available buckets:\", gcs_client.list_buckets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3b948f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fieldwork_processed/2024_02_06-session_0001',\n",
       " 'fieldwork_processed/2024_05_18-session_0001',\n",
       " 'fieldwork_processed/2024_05_18-session_0002',\n",
       " 'fieldwork_processed/2024_05_18-session_0003',\n",
       " 'fieldwork_processed/2024_05_18-session_0004']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUCKET_NAME = \"fieldwork_processed\"  # Update with your bucket name\n",
    "\n",
    "gcs_client.glob(f'{BUCKET_NAME}/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0891ac05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fieldwork_processed/2024_05_18-session_0001/metadata_518_1.yaml',\n",
       " 'fieldwork_processed/2024_05_18-session_0001/rgb_1',\n",
       " 'fieldwork_processed/2024_05_18-session_0001/rgb_1/time_cropped-GX010150.MP4',\n",
       " 'fieldwork_processed/2024_05_18-session_0001/rgb_2',\n",
       " 'fieldwork_processed/2024_05_18-session_0001/rgb_2/time_cropped-GX010150.MP4',\n",
       " 'fieldwork_processed/2024_05_18-session_0001/thermal_1',\n",
       " 'fieldwork_processed/2024_05_18-session_0001/thermal_1/thermal_1_tracks.csv',\n",
       " 'fieldwork_processed/2024_05_18-session_0001/thermal_1/thermal_1_tracks.mp4',\n",
       " 'fieldwork_processed/2024_05_18-session_0001/thermal_1/time_cropped-thermal_8.0_19.0.csv',\n",
       " 'fieldwork_processed/2024_05_18-session_0001/thermal_2',\n",
       " 'fieldwork_processed/2024_05_18-session_0001/thermal_2/thermal_2_tracks.csv',\n",
       " 'fieldwork_processed/2024_05_18-session_0001/thermal_2/thermal_2_tracks.mp4',\n",
       " 'fieldwork_processed/2024_05_18-session_0001/thermal_2/time_cropped-thermal_10.0_20.0.csv']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download Data from Cloud Bucket\n",
    "SESSION_FOLDER = \"2024_05_18-session_0001\"\n",
    "CLOUD_PREFIX = f\"{BUCKET_NAME}/{SESSION_FOLDER}\"  # Update with data folder (session)\n",
    "gcs_client.glob(f\"{CLOUD_PREFIX}/**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ca1927a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_name: metadata_518_1.yaml, suffix: .yaml\n",
      "Downloading file: fieldwork_processed/2024_05_18-session_0001/metadata_518_1.yaml to /Users/dima/git/collab-environment/data/2024_05_18-session_0001/metadata_518_1.yaml\n",
      "local_name: rgb_1, suffix: \n",
      "Creating folder: /Users/dima/git/collab-environment/data/2024_05_18-session_0001/rgb_1\n",
      "local_name: time_cropped-GX010150.MP4, suffix: .MP4\n",
      "Downloading file: fieldwork_processed/2024_05_18-session_0001/rgb_1/time_cropped-GX010150.MP4 to /Users/dima/git/collab-environment/data/2024_05_18-session_0001/rgb_1/time_cropped-GX010150.MP4\n",
      "local_name: rgb_2, suffix: \n",
      "Creating folder: /Users/dima/git/collab-environment/data/2024_05_18-session_0001/rgb_2\n",
      "local_name: time_cropped-GX010150.MP4, suffix: .MP4\n",
      "Downloading file: fieldwork_processed/2024_05_18-session_0001/rgb_2/time_cropped-GX010150.MP4 to /Users/dima/git/collab-environment/data/2024_05_18-session_0001/rgb_2/time_cropped-GX010150.MP4\n",
      "local_name: thermal_1, suffix: \n",
      "Creating folder: /Users/dima/git/collab-environment/data/2024_05_18-session_0001/thermal_1\n",
      "local_name: thermal_1_tracks.csv, suffix: .csv\n",
      "Downloading file: fieldwork_processed/2024_05_18-session_0001/thermal_1/thermal_1_tracks.csv to /Users/dima/git/collab-environment/data/2024_05_18-session_0001/thermal_1/thermal_1_tracks.csv\n",
      "local_name: thermal_1_tracks.mp4, suffix: .mp4\n",
      "Downloading file: fieldwork_processed/2024_05_18-session_0001/thermal_1/thermal_1_tracks.mp4 to /Users/dima/git/collab-environment/data/2024_05_18-session_0001/thermal_1/thermal_1_tracks.mp4\n",
      "local_name: time_cropped-thermal_8.0_19.0.csv, suffix: .csv\n",
      "Downloading file: fieldwork_processed/2024_05_18-session_0001/thermal_1/time_cropped-thermal_8.0_19.0.csv to /Users/dima/git/collab-environment/data/2024_05_18-session_0001/thermal_1/time_cropped-thermal_8.0_19.0.csv\n",
      "local_name: thermal_2, suffix: \n",
      "Creating folder: /Users/dima/git/collab-environment/data/2024_05_18-session_0001/thermal_2\n",
      "local_name: thermal_2_tracks.csv, suffix: .csv\n",
      "Downloading file: fieldwork_processed/2024_05_18-session_0001/thermal_2/thermal_2_tracks.csv to /Users/dima/git/collab-environment/data/2024_05_18-session_0001/thermal_2/thermal_2_tracks.csv\n",
      "local_name: thermal_2_tracks.mp4, suffix: .mp4\n",
      "Downloading file: fieldwork_processed/2024_05_18-session_0001/thermal_2/thermal_2_tracks.mp4 to /Users/dima/git/collab-environment/data/2024_05_18-session_0001/thermal_2/thermal_2_tracks.mp4\n",
      "local_name: time_cropped-thermal_10.0_20.0.csv, suffix: .csv\n",
      "Downloading file: fieldwork_processed/2024_05_18-session_0001/thermal_2/time_cropped-thermal_10.0_20.0.csv to /Users/dima/git/collab-environment/data/2024_05_18-session_0001/thermal_2/time_cropped-thermal_10.0_20.0.csv\n"
     ]
    }
   ],
   "source": [
    "LOCAL_DOWNLOAD_DIR = expand_path(f\"data/{SESSION_FOLDER}\",get_project_root())\n",
    "LOCAL_PROCESSED_DIR = expand_path(f\"data/{SESSION_FOLDER}\",get_project_root())\n",
    "\n",
    "if not LOCAL_DOWNLOAD_DIR.exists():\n",
    "    LOCAL_DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "if not LOCAL_PROCESSED_DIR.exists():\n",
    "    LOCAL_PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for blob in gcs_client.glob(f\"{CLOUD_PREFIX}/**\"):\n",
    "    relative_path = Path(blob).relative_to(f\"{CLOUD_PREFIX}\")\n",
    "    local_name = relative_path.name\n",
    "    suffix = relative_path.suffix\n",
    "    print(f\"local_name: {local_name}, suffix: {suffix}\")\n",
    "    if len(str(suffix))>0:\n",
    "        #print(\"File!\")\n",
    "        parent_folder = relative_path.parent\n",
    "        if not Path(LOCAL_DOWNLOAD_DIR / parent_folder).exists():\n",
    "            print(f\"Creating folder: {LOCAL_DOWNLOAD_DIR / parent_folder}\")\n",
    "            Path(LOCAL_DOWNLOAD_DIR / parent_folder).mkdir(parents=True, exist_ok=True)\n",
    "        # print(f\"parent_folder: {parent_folder}\")\n",
    "        local_path = LOCAL_DOWNLOAD_DIR / parent_folder / local_name\n",
    "        print(f\"Downloading file: {blob} to {local_path}\")\n",
    "        gcs_client.gcs.get_file(blob, str(local_path))\n",
    "    else:\n",
    "        \n",
    "        if not Path(LOCAL_PROCESSED_DIR / relative_path).exists():\n",
    "            print(f\"Creating folder: {LOCAL_PROCESSED_DIR / relative_path}\")\n",
    "            Path(LOCAL_PROCESSED_DIR / relative_path).mkdir(parents=True, exist_ok=True)\n",
    "    # check if there is an extension, if not this is a folder and we need to create it\n",
    "    \n",
    "\n",
    "#print(\"Downloaded files:\", list(LOCAL_DOWNLOAD_DIR.iterdir()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b804e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the Data\n",
    "print(\"Processing data...\")\n",
    "\n",
    "# Validate session structure\n",
    "print(\"Validating session structure...\")\n",
    "validate_session_structure(LOCAL_DOWNLOAD_DIR)\n",
    "\n",
    "#thermal files processing\n",
    "print(\"Processing thermal files...\")\n",
    "process_directory(folder_path=LOCAL_DOWNLOAD_DIR, out_path=LOCAL_DOWNLOAD_DIR, color='magma', preview=True, max_frames=None, fps=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd97256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default parameters for alignment\n",
    "\n",
    "frame_size = (640, 480)  # Default frame size\n",
    "max_frames = 10  # Process all frames by default\n",
    "warp_to = \"rgb\"  # Default warp to rgb, thermal is changing, not rgb\n",
    "rotation_angle = 0.0  # Default rotation angle\n",
    "skip_homography = False  # Default to not skip homography\n",
    "skip_translation = True  # Default to skip translation\n",
    "camera_numbers = [1, 2]  \n",
    "\n",
    "  \n",
    "for camera in camera_numbers:\n",
    "    print(f\"Processing camera {camera}...\")\n",
    "    \n",
    "    # Dynamically find the RGB and thermal MP4 files\n",
    "    rgb_dir = LOCAL_DOWNLOAD_DIR / f\"rgb_{camera}\"\n",
    "    thermal_dir = LOCAL_DOWNLOAD_DIR / f\"thermal_{camera}\"\n",
    "    \n",
    "    # Find the MP4 file in the RGB directory\n",
    "    rgb_video_files = list(rgb_dir.glob(\"*.MP4\")) + list(rgb_dir.glob(\"*.mp4\"))\n",
    "    print('files in rgb_dir:', rgb_video_files)\n",
    "    if len(rgb_video_files) == 0:\n",
    "        print(f\"No MP4 file found in {rgb_dir}. Skipping camera {camera}.\")\n",
    "        continue\n",
    "    elif len(rgb_video_files) > 1:\n",
    "        print(f\"Multiple MP4 files found in {rgb_dir}. Using the first one.\")\n",
    "    rgb_video_path = rgb_video_files[0]\n",
    "    \n",
    "    # Find the MP4 file in the thermal directory\n",
    "    thermal_video_files = list(thermal_dir.glob(\"*.mp4\")) + list(thermal_dir.glob(\"*.MP4\"))\n",
    "    print('files in thermal_dir:', thermal_video_files)\n",
    "    if len(thermal_video_files) == 0:\n",
    "        print(f\"No MP4 file found in {thermal_dir}. Skipping camera {camera}.\")\n",
    "        continue\n",
    "    elif len(thermal_video_files) > 1:\n",
    "        print(f\"Multiple MP4 files found in {thermal_dir}. Using the first one.\")\n",
    "    thermal_video_path = thermal_video_files[0]\n",
    "    \n",
    "    print(f\"RGB video path: {rgb_video_path}\")\n",
    "    print(f\"Thermal video path: {thermal_video_path}\")\n",
    "\n",
    "    output_dir_rgb = LOCAL_PROCESSED_DIR / 'aligned' / f\"rgb_{camera}\"\n",
    "    output_dir_thm = LOCAL_PROCESSED_DIR / 'aligned' / f\"thermal_{camera}\"\n",
    "    output_dir_rgb.mkdir(parents=True, exist_ok=True)\n",
    "    output_dir_thm.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Align videos\n",
    "    print(f\"Aligning videos for camera {camera}...\")\n",
    "\n",
    "    align_videos(\n",
    "        rgb_video_path,\n",
    "        thermal_video_path,\n",
    "        output_dir_rgb,\n",
    "        output_dir_thm,\n",
    "        frame_size=frame_size,\n",
    "        max_frames=max_frames,\n",
    "        warp_to=warp_to,\n",
    "        rotation_angle=rotation_angle,\n",
    "        skip_homography=skip_homography,\n",
    "        skip_translation=skip_translation,\n",
    "    )"
   ]
  },
{
   "cell_type": "code",
   "execution_count": null,
   "id": "detection-and-tracking",
   "metadata": {},
   "outputs": [],
   "source": [
       "from scripts.local_model_inference import process_video_with_rfdetr\n",
       "\n",
       "# Detection and tracking\n",
       "print(\"Running detection and tracking...\")\n",
       "for camera in camera_numbers:\n",
       "    print(f\"Running detection and tracking on: thermal_{camera}\")\n",
       "    \n",
       "    # Define paths for the thermal video and model inference\n",
       "    thermal_video_path = LOCAL_PROCESSED_DIR / 'aligned' / f\"thermal_{camera}\" / f\"warped_thermal_{camera}.mp4\"\n",
       "    if not thermal_video_path.exists():\n",
       "        print(f\"Thermal video not found for camera {camera}. Skipping...\")\n",
       "        continue\n",
       "\n",
       "    # Run local_model_inference script\n",
       "    try:\n",
       "        output_csv_path = LOCAL_PROCESSED_DIR / 'aligned' / f\"thermal_{camera}\" / \"output_results.csv\"\n",
       "        output_video_path = LOCAL_PROCESSED_DIR / 'aligned' / f\"thermal_{camera}\" / \"annotated_warped_thermal.mp4\"\n",
       "        checkpoint_path = \"scripts/model/weights.pt\"\n",
       "\n",
       "        process_video_with_rfdetr(\n",
       "            video_path=thermal_video_path,\n",
       "            output_csv_path=output_csv_path,\n",
       "            output_video_path=output_video_path,\n",
       "            checkpoint_path=checkpoint_path,\n",
       "            confidence=0.5\n",
       "        )\n",
       "    except Exception as e:\n",
       "        print(f\"Error during object detection for camera {camera}: {e}\")\n",
       "        continue\n",
       "\n",
       "    # Run tracking\n",
       "    print(f\"Running tracking on: thermal_{camera}\")\n",
       "    run_tracking(LOCAL_PROCESSED_DIR, \"thermal\", camera)\n",
       "\n",
       "    tracked_csv = LOCAL_PROCESSED_DIR / 'aligned' / f\"thermal_{camera}\" / f\"thermal_{camera}_tracks.csv\"\n",
       "    if not tracked_csv.exists():\n",
       "        print(f\"Tracking CSV not found for camera {camera}. Skipping visualization.\")\n",
       "        continue\n",
       "\n",
       "    # Visualization\n",
       "    visualize_detections_from_video(\n",
       "        csv_path=tracked_csv,\n",
       "        video_path=thermal_video_path,\n",
       "        output_video_path=LOCAL_PROCESSED_DIR / 'aligned' / f\"thermal_{camera}\" / f\"visualized_thermal_{camera}.mp4\"\n",
       "    )\n",
       "    print(f\"Visualizing tracks for rgb camera {camera}...\")\n",
       "    overlay_tracks_on_video(\n",
       "        csv_path=tracked_csv,\n",
       "        frame_dir=LOCAL_PROCESSED_DIR / 'aligned' / f\"rgb_{camera}\" / 'annotated_frames',\n",
       "        output_video=LOCAL_PROCESSED_DIR / 'aligned' / f\"rgb_{camera}\" / f\"overlayed_tracks_{camera}.mp4\"\n",
       "    )\n"
]
{
   "cell_type": "code",
   "execution_count": null,
   "id": "detection-tracking",
   "metadata": {},
   "outputs": [],
   "source": [
       "from scripts.local_model_inference import process_video_with_rfdetr\n",
       "\n",
       "# Detection and tracking\n",
       "print(\"Running detection and tracking...\")\n",
       "for camera in camera_numbers:\n",
       "    print(f\"Running detection and tracking on: thermal_{camera}\")\n",
       "    \n",
       "    # Define paths for the thermal video and model inference\n",
       "    thermal_video_path = LOCAL_PROCESSED_DIR / 'aligned' / f\"thermal_{camera}\" / f\"warped_thermal_{camera}.mp4\"\n",
       "    if not thermal_video_path.exists():\n",
       "        print(f\"Thermal video not found for camera {camera}. Skipping...\")\n",
       "        continue\n",
       "\n",
       "    # Run local_model_inference script\n",
       "    try:\n",
       "        output_csv_path = LOCAL_PROCESSED_DIR / 'aligned' / f\"thermal_{camera}\" / \"output_results.csv\"\n",
       "        output_video_path = LOCAL_PROCESSED_DIR / 'aligned' / f\"thermal_{camera}\" / \"annotated_warped_thermal.mp4\"\n",
       "        checkpoint_path = \"scripts/model/weights.pt\"\n",
       "\n",
       "        process_video_with_rfdetr(\n",
       "            video_path=thermal_video_path,\n",
       "            output_csv_path=output_csv_path,\n",
       "            output_video_path=output_video_path,\n",
       "            checkpoint_path=checkpoint_path,\n",
       "            confidence=0.5\n",
       "        )\n",
       "    except Exception as e:\n",
       "        print(f\"Error during object detection for camera {camera}: {e}\")\n",
       "        continue\n",
       "\n",
       "    # Run tracking\n",
       "    print(f\"Running tracking on: thermal_{camera}\")\n",
       "    run_tracking(LOCAL_PROCESSED_DIR, \"thermal\", camera)\n",
       "\n",
       "    tracked_csv = LOCAL_PROCESSED_DIR / 'aligned' / f\"thermal_{camera}\" / f\"thermal_{camera}_tracks.csv\"\n",
       "    if not tracked_csv.exists():\n",
       "        print(f\"Tracking CSV not found for camera {camera}. Skipping visualization.\")\n",
       "        continue\n",
       "\n",
       "    # Visualization\n",
       "    visualize_detections_from_video(\n",
       "        csv_path=tracked_csv,\n",
       "        video_path=thermal_video_path,\n",
       "        output_video_path=LOCAL_PROCESSED_DIR / 'aligned' / f\"thermal_{camera}\" / f\"visualized_thermal_{camera}.mp4\"\n",
       "    )\n",
       "    print(f\"Visualizing tracks for rgb camera {camera}...\")\n",
       "    overlay_tracks_on_video(\n",
       "        csv_path=tracked_csv,\n",
       "        frame_dir=LOCAL_PROCESSED_DIR / 'aligned' / f\"rgb_{camera}\" / 'annotated_frames',\n",
       "        output_video=LOCAL_PROCESSED_DIR / 'aligned' / f\"rgb_{camera}\" / f\"overlayed_tracks_{camera}.mp4\"\n",
       "\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146dc8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Processed Data to Cloud Bucket\n",
    "CLOUD_PROCESSED_PREFIX = \"your-cloud-processed-prefix\"  # Update with your processed data prefix\n",
    "for file in LOCAL_PROCESSED_DIR.iterdir():\n",
    "    cloud_path = f\"{BUCKET_NAME}/{CLOUD_PROCESSED_PREFIX}/{file.name}\"\n",
    "    gcs_client.upload_file(str(file), cloud_path)\n",
    "\n",
    "print(\"Uploaded processed files:\", list(LOCAL_PROCESSED_DIR.iterdir()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
