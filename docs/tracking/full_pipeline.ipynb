{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a20766",
   "metadata": {},
   "source": [
    "# Full Tracker: Download, Process, and Upload Data\n",
    "This notebook demonstrates the full pipeline for handling raw data:\n",
    "1. Download data from a cloud bucket.\n",
    "2. Process the data (e.g., align videos, run detection, and tracking).\n",
    "3. Upload the processed data back to the cloud bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00d07572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Dict, Tuple\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import Custom Scripts\n",
    "from collab_env.tracking.thermal_processing import process_directory, validate_session_structure\n",
    "from collab_env.tracking.align_videos_manually import align_videos, step1_crop_and_prepare, step2_spatial_alignment, save_warped_video\n",
    "from collab_env.tracking.local_model_tracking import run_tracking, overlay_tracks_on_video, visualize_detections_from_video\n",
    "import subprocess\n",
    "\n",
    "from collab_env.data.file_utils import expand_path, get_project_root\n",
    "from collab_env.data.gcs_utils import GCSClient\n",
    "\n",
    "skip_download = True\n",
    "skip_thermal_extraction = True\n",
    "\n",
    "# Reload helper for dev work\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "888d4395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-28 14:51:42.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcollab_env.data.gcs_utils\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mUsing credentials from /Users/dima/git/collab-environment/config-local/collab-data-463313-c340ad86b28e.json\u001b[0m\n",
      "\u001b[32m2025-07-28 14:51:42.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcollab_env.data.gcs_utils\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mUsing project collab-data-463313\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Setup Configuration\n",
    "load_dotenv()\n",
    "data_key = expand_path(os.environ.get(\"COLLAB_DATA_KEY\", \"\"), get_project_root())\n",
    "PROJECT_ID = \"collab-data-463313\"\n",
    "\n",
    "CREDENTIALS_PATH = expand_path(data_key.as_posix(), get_project_root())\n",
    "\n",
    "# Connect to Google Cloud Storage\n",
    "gcs_client = GCSClient(\n",
    "    project_id=PROJECT_ID,\n",
    "    credentials_path=CREDENTIALS_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94fb308b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available buckets: ['fieldwork_curated', 'fieldwork_processed']\n"
     ]
    }
   ],
   "source": [
    "# Verify connection\n",
    "print(\"Available buckets:\", gcs_client.list_buckets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3b948f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fieldwork_curated/2024_02_06-session_0001',\n",
       " 'fieldwork_curated/2024_05_18-session_0001',\n",
       " 'fieldwork_curated/2024_05_18-session_0002',\n",
       " 'fieldwork_curated/2024_05_18-session_0003',\n",
       " 'fieldwork_curated/2024_05_18-session_0004',\n",
       " 'fieldwork_curated/2024_05_18-session_0005',\n",
       " 'fieldwork_curated/2024_05_18-session_0006',\n",
       " 'fieldwork_curated/2024_05_19-session_0001',\n",
       " 'fieldwork_curated/STRUCTURE.md']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUCKET_NAME = \"fieldwork_curated\"  # Update with your bucket name\n",
    "\n",
    "gcs_client.glob(f'{BUCKET_NAME}/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0891ac05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fieldwork_curated/2024_02_06-session_0001/',\n",
       " 'fieldwork_curated/2024_02_06-session_0001/metadata_206_1.yaml',\n",
       " 'fieldwork_curated/2024_02_06-session_0001/rgb_1',\n",
       " 'fieldwork_curated/2024_02_06-session_0001/rgb_1/',\n",
       " 'fieldwork_curated/2024_02_06-session_0001/rgb_1/GX010119.MP4',\n",
       " 'fieldwork_curated/2024_02_06-session_0001/rgb_2',\n",
       " 'fieldwork_curated/2024_02_06-session_0001/rgb_2/',\n",
       " 'fieldwork_curated/2024_02_06-session_0001/rgb_2/GX010119.MP4',\n",
       " 'fieldwork_curated/2024_02_06-session_0001/thermal_1',\n",
       " 'fieldwork_curated/2024_02_06-session_0001/thermal_1/',\n",
       " 'fieldwork_curated/2024_02_06-session_0001/thermal_1/20240206071804298.csq',\n",
       " 'fieldwork_curated/2024_02_06-session_0001/thermal_2',\n",
       " 'fieldwork_curated/2024_02_06-session_0001/thermal_2/',\n",
       " 'fieldwork_curated/2024_02_06-session_0001/thermal_2/20240206071808444.csq']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download Data from Cloud Bucket\n",
    "SESSION_FOLDER = \"2024_02_06-session_0001\"\n",
    "CLOUD_PREFIX = f\"{BUCKET_NAME}/{SESSION_FOLDER}\"  # Update with data folder (session)\n",
    "gcs_client.glob(f\"{CLOUD_PREFIX}/**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa4e7573",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DOWNLOAD_DIR = expand_path(f\"data/raw/{SESSION_FOLDER}\",get_project_root())\n",
    "LOCAL_PROCESSED_DIR = expand_path(f\"data/processed/{SESSION_FOLDER}\",get_project_root())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ca1927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_download:\n",
    "    if not LOCAL_DOWNLOAD_DIR.exists():\n",
    "        LOCAL_DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    if not LOCAL_PROCESSED_DIR.exists():\n",
    "        LOCAL_PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for blob in gcs_client.glob(f\"{CLOUD_PREFIX}/**\"):\n",
    "        relative_path = Path(blob).relative_to(f\"{CLOUD_PREFIX}\")\n",
    "        local_name = relative_path.name\n",
    "        suffix = relative_path.suffix\n",
    "        print(f\"local_name: {local_name}, suffix: {suffix}\")\n",
    "        if len(str(suffix))>0:\n",
    "            #print(\"File!\")\n",
    "            parent_folder = relative_path.parent\n",
    "            if not Path(LOCAL_DOWNLOAD_DIR / parent_folder).exists():\n",
    "                print(f\"Creating folder: {LOCAL_DOWNLOAD_DIR / parent_folder}\")\n",
    "                Path(LOCAL_DOWNLOAD_DIR / parent_folder).mkdir(parents=True, exist_ok=True)\n",
    "            # print(f\"parent_folder: {parent_folder}\")\n",
    "            local_path = LOCAL_DOWNLOAD_DIR / parent_folder / local_name\n",
    "            print(f\"Downloading file: {blob} to {local_path}\")\n",
    "            gcs_client.gcs.get_file(blob, str(local_path))\n",
    "        else:\n",
    "            \n",
    "            if not Path(LOCAL_PROCESSED_DIR / relative_path).exists():\n",
    "                print(f\"Creating folder: {LOCAL_PROCESSED_DIR / relative_path}\")\n",
    "                Path(LOCAL_PROCESSED_DIR / relative_path).mkdir(parents=True, exist_ok=True)\n",
    "        # check if there is an extension, if not this is a folder and we need to create it\n",
    "        \n",
    "\n",
    "    #print(\"Downloaded files:\", list(LOCAL_DOWNLOAD_DIR.iterdir()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26eca37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/dima/git/collab-environment/data/raw/2024_02_06-session_0001')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOCAL_DOWNLOAD_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2e8dcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating session structure...\n",
      "Session structure is valid.\n",
      "Issues found: None\n"
     ]
    }
   ],
   "source": [
    "# Validate session structure\n",
    "print(\"Validating session structure...\")\n",
    "issues = validate_session_structure(LOCAL_DOWNLOAD_DIR)\n",
    "print(f\"Issues found: {issues if len(issues)>0 else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09b804e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_thermal_extraction:\n",
    "    #thermal files processing\n",
    "    print(\"Processing thermal files...\")\n",
    "\n",
    "    # call with preview=False to choose the vmin/vmax automatically, otherwise the user will be asked to choose the vmin/vmax\n",
    "    # process_directory(folder_path=LOCAL_DOWNLOAD_DIR, out_path=LOCAL_DOWNLOAD_DIR, color='magma', preview=True, max_frames=None, fps=30)\n",
    "    process_directory(folder_path=LOCAL_DOWNLOAD_DIR, out_path=LOCAL_PROCESSED_DIR, color='magma', preview=True, max_frames=100, fps=30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cd97256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing camera 1...\n",
      "files in rgb_dir: [PosixPath('/Users/dima/git/collab-environment/data/raw/2024_02_06-session_0001/rgb_1/GX010119.MP4')]\n",
      "files in thermal_dir: [PosixPath('/Users/dima/git/collab-environment/data/processed/2024_02_06-session_0001/thermal_1/thermal_-20_20.mp4'), PosixPath('/Users/dima/git/collab-environment/data/processed/2024_02_06-session_0001/thermal_1/thermal_-5_21.mp4')]\n",
      "Multiple MP4 files found in /Users/dima/git/collab-environment/data/processed/2024_02_06-session_0001/thermal_1. Using the first one.\n",
      "RGB video path: /Users/dima/git/collab-environment/data/raw/2024_02_06-session_0001/rgb_1/GX010119.MP4\n",
      "Thermal video path: /Users/dima/git/collab-environment/data/processed/2024_02_06-session_0001/thermal_1/thermal_-20_20.mp4\n",
      "Aligning videos for camera 1...\n",
      "Draw a rectangle on the LEFT (RGB) image to crop. Press ENTER or SPACE when done.\n",
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n",
      "Selected crop (on RGB, resized): (223, 134, 182, 156)\n",
      "Selected crop (on RGB, original): (1850, 834, 1510, 971)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping/Rotating video: 100%|██████████| 10/10 [00:00<00:00, 30.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved cropped/rotated video to /Users/dima/git/collab-environment/data/processed/2024_02_06-session_0001/aligned/rgb_1/cropped_rgb.mp4\n",
      "✅ Saved cropped RGB video to /Users/dima/git/collab-environment/data/processed/2024_02_06-session_0001/aligned/rgb_1/cropped_rgb.mp4\n",
      "Skipping translation step.\n",
      "Click at least 4 corresponding points in the overlay. Adjust alpha with [ and ]. Press any key when done.\n",
      "Now select the same 8 points in the other image, in the same order.\n",
      "Click at least 4 corresponding points in the image, then press any key to continue.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Invalid point selection for homography.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Align videos\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAligning videos for camera \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcamera\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 50\u001b[0m \u001b[43malign_videos\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrgb_video_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthermal_video_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir_rgb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir_thm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarp_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarp_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrotation_angle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrotation_angle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_homography\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_homography\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_translation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_translation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/collab-environment/collab_env/tracking/align_videos_manually.py:489\u001b[0m, in \u001b[0;36malign_videos\u001b[0;34m(rgb_video_path, thermal_video_path, output_dir_rgb, output_dir_thm, frame_size, max_frames, warp_to, rotation_angle, skip_homography, skip_translation)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21malign_videos\u001b[39m(rgb_video_path, thermal_video_path, output_dir_rgb, output_dir_thm,\n\u001b[1;32m    485\u001b[0m                  frame_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m640\u001b[39m, \u001b[38;5;241m480\u001b[39m), max_frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, warp_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthermal\u001b[39m\u001b[38;5;124m\"\u001b[39m, rotation_angle\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, skip_homography\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, skip_translation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    487\u001b[0m     cropped_rgb_path \u001b[38;5;241m=\u001b[39m step1_crop_and_prepare(rgb_video_path, thermal_video_path, output_dir_rgb, output_dir_thm, frame_size, max_frames)\n\u001b[0;32m--> 489\u001b[0m     H \u001b[38;5;241m=\u001b[39m \u001b[43mstep2_spatial_alignment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcropped_rgb_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthermal_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarp_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_homography\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_translation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_translation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m     warped_thermal_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir_thm, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarped_thermal.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    492\u001b[0m     save_warped_video(thermal_video_path, warped_thermal_path, H, frame_size, max_frames)\n",
      "File \u001b[0;32m~/git/collab-environment/collab_env/tracking/align_videos_manually.py:409\u001b[0m, in \u001b[0;36mstep2_spatial_alignment\u001b[0;34m(cropped_rgb_path, thermal_video_path, frame_size, warp_to, skip_homography, skip_translation)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep2_spatial_alignment\u001b[39m(cropped_rgb_path, thermal_video_path, frame_size, warp_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthermal\u001b[39m\u001b[38;5;124m\"\u001b[39m, skip_homography\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, skip_translation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 409\u001b[0m     H \u001b[38;5;241m=\u001b[39m \u001b[43mget_homography_with_translation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcropped_rgb_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthermal_video_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarp_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarp_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_homography\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_homography\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_translation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_translation\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Transformation matrix:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, H)\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m H\n",
      "File \u001b[0;32m~/git/collab-environment/collab_env/tracking/align_videos_manually.py:290\u001b[0m, in \u001b[0;36mget_homography_with_translation\u001b[0;34m(rgb_video_path, thermal_video_path, frame_size, warp_to, skip_homography, skip_translation)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m H_full\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid point selection for homography.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Invalid point selection for homography."
     ]
    }
   ],
   "source": [
    "#default parameters for alignment\n",
    "\n",
    "frame_size = (640, 480)  # Default frame size\n",
    "max_frames = 10  # Process all frames by default\n",
    "warp_to = \"rgb\"  # Default warp to rgb, thermal is changing, not rgb\n",
    "rotation_angle = 0.0  # Default rotation angle\n",
    "skip_homography = False  # Default to not skip homography\n",
    "skip_translation = True  # Default to skip translation\n",
    "camera_numbers = [1, 2]  \n",
    "\n",
    "  \n",
    "for camera in camera_numbers:\n",
    "    print(f\"Processing camera {camera}...\")\n",
    "    \n",
    "    # Dynamically find the RGB and thermal MP4 files\n",
    "    rgb_dir = LOCAL_DOWNLOAD_DIR / f\"rgb_{camera}\"\n",
    "    thermal_dir = LOCAL_PROCESSED_DIR / f\"thermal_{camera}\"\n",
    "    \n",
    "    # Find the MP4 file in the RGB directory\n",
    "    rgb_video_files = list(rgb_dir.glob(\"*.MP4\")) + list(rgb_dir.glob(\"*.mp4\"))\n",
    "    print('files in rgb_dir:', rgb_video_files)\n",
    "    if len(rgb_video_files) == 0:\n",
    "        print(f\"No MP4 file found in {rgb_dir}. Skipping camera {camera}.\")\n",
    "        continue\n",
    "    elif len(rgb_video_files) > 1:\n",
    "        print(f\"Multiple MP4 files found in {rgb_dir}. Using the first one.\")\n",
    "    rgb_video_path = rgb_video_files[0]\n",
    "    \n",
    "    # Find the MP4 file in the thermal directory\n",
    "    thermal_video_files = list(thermal_dir.glob(\"*.mp4\")) + list(thermal_dir.glob(\"*.MP4\"))\n",
    "    print('files in thermal_dir:', thermal_video_files)\n",
    "    if len(thermal_video_files) == 0:\n",
    "        print(f\"No MP4 file found in {thermal_dir}. Skipping camera {camera}.\")\n",
    "        continue\n",
    "    elif len(thermal_video_files) > 1:\n",
    "        print(f\"Multiple MP4 files found in {thermal_dir}. Using the first one.\")\n",
    "    thermal_video_path = thermal_video_files[0]\n",
    "    \n",
    "    print(f\"RGB video path: {rgb_video_path}\")\n",
    "    print(f\"Thermal video path: {thermal_video_path}\")\n",
    "\n",
    "    output_dir_rgb = LOCAL_PROCESSED_DIR / 'aligned' / f\"rgb_{camera}\"\n",
    "    output_dir_thm = LOCAL_PROCESSED_DIR / 'aligned' / f\"thermal_{camera}\"\n",
    "    output_dir_rgb.mkdir(parents=True, exist_ok=True)\n",
    "    output_dir_thm.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Align videos\n",
    "    print(f\"Aligning videos for camera {camera}...\")\n",
    "\n",
    "    align_videos(\n",
    "        rgb_video_path,\n",
    "        thermal_video_path,\n",
    "        output_dir_rgb,\n",
    "        output_dir_thm,\n",
    "        frame_size=frame_size,\n",
    "        max_frames=max_frames,\n",
    "        warp_to=warp_to,\n",
    "        rotation_angle=rotation_angle,\n",
    "        skip_homography=skip_homography,\n",
    "        skip_translation=skip_translation,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detection-tracking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.local_model_inference import process_video_with_rfdetr\n",
    "\n",
    "# Detection and tracking\n",
    "print(\"Running detection and tracking...\")\n",
    "for camera in camera_numbers:\n",
    "    print(f\"Running detection and tracking on: thermal_{camera}\")\n",
    "    \n",
    "    # Define paths for the thermal video and model inference\n",
    "    thermal_video_path = LOCAL_PROCESSED_DIR / 'aligned' / f\"thermal_{camera}\" / f\"warped_thermal_{camera}.mp4\"\n",
    "    if not thermal_video_path.exists():\n",
    "        print(f\"Thermal video not found for camera {camera}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Run local_model_inference script\n",
    "    try:\n",
    "        output_csv_path = LOCAL_PROCESSED_DIR / 'aligned' / f\"thermal_{camera}\" / \"output_results.csv\"\n",
    "        output_video_path = LOCAL_PROCESSED_DIR / 'aligned' / f\"thermal_{camera}\" / \"annotated_warped_thermal.mp4\"\n",
    "        checkpoint_path = \"scripts/model/weights.pt\"\n",
    "\n",
    "        process_video_with_rfdetr(\n",
    "            video_path=thermal_video_path,\n",
    "            output_csv_path=output_csv_path,\n",
    "            output_video_path=output_video_path,\n",
    "            checkpoint_path=checkpoint_path,\n",
    "            confidence=0.5\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error during object detection for camera {camera}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Run tracking\n",
    "    print(f\"Running tracking on: thermal_{camera}\")\n",
    "    run_tracking(LOCAL_PROCESSED_DIR, \"thermal\", camera)\n",
    "\n",
    "    tracked_csv = LOCAL_PROCESSED_DIR / 'aligned' / f\"thermal_{camera}\" / f\"thermal_{camera}_tracks.csv\"\n",
    "    if not tracked_csv.exists():\n",
    "        print(f\"Tracking CSV not found for camera {camera}. Skipping visualization.\")\n",
    "        continue\n",
    "\n",
    "    # Visualization\n",
    "    visualize_detections_from_video(\n",
    "        csv_path=tracked_csv,\n",
    "        video_path=thermal_video_path,\n",
    "        output_video_path=LOCAL_PROCESSED_DIR / 'aligned' / f\"thermal_{camera}\" / f\"visualized_thermal_{camera}.mp4\"\n",
    "    )\n",
    "    print(f\"Visualizing tracks for rgb camera {camera}...\")\n",
    "    overlay_tracks_on_video(\n",
    "        csv_path=tracked_csv,\n",
    "        frame_dir=LOCAL_PROCESSED_DIR / 'aligned' / f\"rgb_{camera}\" / 'annotated_frames',\n",
    "        output_video=LOCAL_PROCESSED_DIR / 'aligned' / f\"rgb_{camera}\" / f\"overlayed_tracks_{camera}.mp4\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146dc8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Processed Data to Cloud Bucket\n",
    "CLOUD_PROCESSED_PREFIX = \"your-cloud-processed-prefix\"  # Update with your processed data prefix\n",
    "for file in LOCAL_PROCESSED_DIR.iterdir():\n",
    "    cloud_path = f\"{BUCKET_NAME}/{CLOUD_PROCESSED_PREFIX}/{file.name}\"\n",
    "    gcs_client.upload_file(str(file), cloud_path)\n",
    "\n",
    "print(\"Uploaded processed files:\", list(LOCAL_PROCESSED_DIR.iterdir()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
