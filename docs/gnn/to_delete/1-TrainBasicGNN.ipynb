{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cd895be-ab28-49e9-9581-ffbb3513a3a6",
   "metadata": {},
   "source": [
    "# Basic demo of training GNN on boid model.\n",
    "All the scripts are in **scripts.gnn.gnn** and **scripts.gnn.gnn_definition**.\n",
    "The scripts build barebone GNN network architecture, handling of discrete data. \n",
    "The notebook illustrates training and testing and demos of single-frame prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdefeac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e23875c-81f4-4658-babe-f687072f7d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "script_path = os.path.realpath(os.path.dirname(__name__))\n",
    "os.chdir(script_path)\n",
    "sys.path.append(\"/workspace/collab-environment/\")\n",
    "sys.path.append(\"/workspace/collab-environment/collab_env/gnn\")\n",
    "sys.path.append(\"/workspace/collab-environment/collab_env/data/boids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1451bcb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from typing import Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as functional\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from collab_env.data.file_utils import expand_path, get_project_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cad07db",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gnn_definition'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollab_env\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_adjcency_from_debug, plot_log_loss, train_rules_gnn, load_model, save_model, debug_result2prediction\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollab_env\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgnn_definition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GNN, Lazy\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollab_env\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mboids\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manimal_simulation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m visualize_graph_2sets\n",
      "File \u001b[0;32m~/git/collab-environment/collab_env/gnn/gnn.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollab_env\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutility\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m handle_discrete_data, v_function_2_vminushalf\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgc\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgnn_definition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GNN, Lazy\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollab_env\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m expand_path, get_project_root\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild_edge_index\u001b[39m(positions, visual_range):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gnn_definition'"
     ]
    }
   ],
   "source": [
    "from collab_env.gnn.gnn import get_adjcency_from_debug, plot_log_loss, train_rules_gnn, load_model, save_model, debug_result2prediction\n",
    "from collab_env.gnn.gnn_definition import GNN, Lazy\n",
    "from collab_env.data.boids.animal_simulation import visualize_graph_2sets\n",
    "from collab_env.gnn.utility import dataset2testloader\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d34783",
   "metadata": {},
   "source": [
    "### 1. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f1d272-4a0a-4500-9a97-b1ddddf36513",
   "metadata": {},
   "source": [
    "#### (A) Boid with boundary\n",
    "#### (B) Independent with boundary\n",
    "#### (C) Boid with boundary and food\n",
    "#### (D) Independent with boundary and food\n",
    "#### (E) Boid with boundary and strong influence food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2599830c-3e1f-430d-b6e6-6249921eac90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/conda/envs/gnn/lib/python3.13/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "data_names = ['boid_single_species_basic', 'boid_single_species_independent', # without food\n",
    "              'boid_food_basic_alignment', 'boid_food_basic_independent', # with food\n",
    "              'boid_food_strong'] # with food, strong influence\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "data = {}\n",
    "\n",
    "for data_name in data_names:\n",
    "    file_name = f'{data_name}.pt'\n",
    "    config_name = f'{data_name}_config.pt'\n",
    "    \n",
    "    dataset = torch.load(expand_path(\n",
    "            \"simulated_data/\" + file_name, get_project_root()), weights_only = False)\n",
    "    species_configs = torch.load(expand_path(\n",
    "            \"simulated_data/\" + config_name, get_project_root()), weights_only = False)\n",
    "\n",
    "    test_loader, train_loader = dataset2testloader(dataset, batch_size = batch_size,\n",
    "                                                   return_train = True)\n",
    "\n",
    "    data[data_name] = {}\n",
    "    data[data_name][\"data_name\"] = data_name\n",
    "    data[data_name][\"file_name\"] = file_name\n",
    "    data[data_name][\"config_name\"] = config_name\n",
    "    data[data_name][\"dataset\"] = dataset\n",
    "    data[data_name][\"species_configs\"] = species_configs\n",
    "    data[data_name]['test_loader'] = test_loader\n",
    "    data[data_name]['train_loader'] = train_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c034e2-d4a0-416a-8b97-9e9335524dd7",
   "metadata": {},
   "source": [
    "### 2. Train GNN and our lazyGNN\n",
    "The lazy model only outputs a zero acceleration at all frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "57305ffe-962e-4207-b15f-4442d98ad46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_specs(data_name, model_name,\n",
    "               noise_level, head, visual_range, epoch):\n",
    "    \"\"\"\n",
    "    data_name: name of the dataset\n",
    "    model_name: name of th\n",
    "    \"\"\"\n",
    "\n",
    "    if \"food\" in data_name:\n",
    "        in_node_dim = 20\n",
    "    else:\n",
    "        in_node_dim = 19\n",
    "\n",
    "    if \"lazy\" in model_name:\n",
    "        model_spec_lazy = {\n",
    "            \"model_name\": \"lazy\",\n",
    "            \"prediction_integration\": \"Euler\",  # predict model acceleration\n",
    "            \"input_differentiation\":\"finite\",\n",
    "            \"in_node_dim\": 3,\n",
    "            \"start_frame\": 3,\n",
    "            \"heads\": 1}\n",
    "\n",
    "        train_spec_lazy = {\n",
    "            \"lr\": None,\n",
    "            \"visual_range\": visual_range,\n",
    "            \"sigma\": sigma,\n",
    "            \"epochs\": 1}\n",
    "        \n",
    "        return model_spec_gnn, train_spec_gnn\n",
    "    \n",
    "    model_spec_gnn = {\n",
    "        \"model_name\": \"vpluspplus_a\",\n",
    "        \"node_feature_function\": \"vel_plus_pos_plus\",  # features are velocity(t-2), velocity(t-1), velocity(t)\n",
    "        \"node_prediction\": \"acc\",  # predict model acceleration\n",
    "        \"prediction_integration\": \"Euler\",  # predict model acceleration\n",
    "        \"input_differentiation\": \"finite\",\n",
    "        \"in_node_dim\": in_node_dim,\n",
    "        \"start_frame\": 3,\n",
    "        \"heads\": head\n",
    "    }\n",
    "\n",
    "    train_spec_gnn = {\n",
    "        \"lr\": 1e-4,\n",
    "        \"visual_range\": visual_range,\n",
    "        \"epochs\": epoch,\n",
    "        \"sigma\": noise_level,\n",
    "        \"training\": True\n",
    "    }\n",
    "    \n",
    "    return model_spec_gnn, train_spec_gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b031825c-acbc-491e-b85a-696a978ede53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_models(model_name, model_spec, train_spec):\n",
    "    gnn_model: torch.nn.Module | None = None\n",
    "        \n",
    "    # initialize models\n",
    "    if \"lazy\" in model_name:\n",
    "        training = False\n",
    "        gnn_model = Lazy(\n",
    "            **model_spec\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        training = True\n",
    "        gnn_model = GNN(\n",
    "            **model_spec\n",
    "        )\n",
    "\n",
    "    train_spec[\"training\"] = training\n",
    "\n",
    "    return gnn_model, train_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4aeafe19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(data, model_spec, train_spec, seed, save_name_postfix):\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.manual_seed(seed)  # PyTorch CPU and CUDA\n",
    "\n",
    "    m = model_spec[\"model_name\"]\n",
    "        \n",
    "    result = {}\n",
    "    \n",
    "    gnn_model, train_spec = initialize_models(m, model_spec, train_spec)\n",
    "    \n",
    "    # data\n",
    "    data_name = data['data_name']\n",
    "    train_loader = data['train_loader']\n",
    "    species_dim = len(data['species_configs'].keys())\n",
    "        \n",
    "    \n",
    "    # train models\n",
    "    (result[\"train_losses\"], result[\"model\"], result[\"debug_result\"]) = (\n",
    "        train_rules_gnn(\n",
    "            gnn_model,\n",
    "            train_loader,\n",
    "            species_dim = species_dim,\n",
    "            **train_spec\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    #models[m][\"W_input\"], models[m][\"W_output\"] = get_adjcency_from_debug(\n",
    "    #    models[m][\"debug_result\"], train_loader, visual_range\n",
    "    #)\n",
    "\n",
    "    gnn_model = result[\"model\"]\n",
    "    noise_level = train_spec[\"sigma\"]\n",
    "        \n",
    "    file_name = f\"{data_name}_{m}_{save_name_postfix}_seed{seed}\"\n",
    "    save_model(result[\"model\"], model_spec, train_spec, file_name)\n",
    "    \n",
    "    return np.sum(result[\"train_losses\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5c634751-2d2c-4c4a-9733-d5fa04052e30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "\n",
      "\n",
      "batch 0\n",
      "\n",
      "\n",
      "batch 1\n",
      "\n",
      "\n",
      "batch 2\n",
      "\n",
      "\n",
      "batch 3\n",
      "\n",
      "\n",
      "batch 4\n",
      "\n",
      "\n",
      "Epoch 000 | Train: 0.0031\n",
      "Saved model to /workspace/collab-environment/trained_models/boid_single_species_basic_vpluspplus_a_noise0_head1_visual_range0.2_seed0.pt.\n",
      "epoch 0\n",
      "\n",
      "\n",
      "batch 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[126]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m save_name_postfix = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnoise\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnoise\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_head\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhead\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_visual_range\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvisual_range\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(SEED_NUM):\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_name_postfix\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[123]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(data, model_spec, train_spec, seed, save_name_postfix)\u001b[39m\n\u001b[32m     14\u001b[39m species_dim = \u001b[38;5;28mlen\u001b[39m(data[\u001b[33m'\u001b[39m\u001b[33mspecies_configs\u001b[39m\u001b[33m'\u001b[39m].keys())\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# train models\u001b[39;00m\n\u001b[32m     18\u001b[39m (result[\u001b[33m\"\u001b[39m\u001b[33mtrain_losses\u001b[39m\u001b[33m\"\u001b[39m], result[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], result[\u001b[33m\"\u001b[39m\u001b[33mdebug_result\u001b[39m\u001b[33m\"\u001b[39m]) = (\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[43mtrain_rules_gnn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgnn_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43mspecies_dim\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecies_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrain_spec\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     )\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m#models[m][\"W_input\"], models[m][\"W_output\"] = get_adjcency_from_debug(\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m#    models[m][\"debug_result\"], train_loader, visual_range\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m#)\u001b[39;00m\n\u001b[32m     31\u001b[39m gnn_model = result[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/collab-environment/collab_env/gnn/gnn.py:571\u001b[39m, in \u001b[36mtrain_rules_gnn\u001b[39m\u001b[34m(model, dataloader, visual_range, epochs, lr, training, full_frames, species_dim, sigma, device, aux_data, rollout, rollout_everyother, ablate_boid_interaction)\u001b[39m\n\u001b[32m    567\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    569\u001b[39m     S, Frame, N, _ = position.shape\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m     (loss, debug_result_all[ep][batch_idx], model) = \u001b[43mrun_gnn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m        \u001b[49m\u001b[43mspecies_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m        \u001b[49m\u001b[43mspecies_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvisual_range\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisual_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[43m        \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfull_frames\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrollout\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrollout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrollout_everyother\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrollout_everyother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mablate_boid_interaction\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mablate_boid_interaction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    586\u001b[39m     train_losses_by_batch.append(loss)\n\u001b[32m    588\u001b[39m train_losses.append(train_losses_by_batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:73\u001b[39m, in \u001b[36mrun_gnn\u001b[39m\u001b[34m(model, position, species_idx, species_dim, visual_range, sigma, device, training, lr, debug_result, full_frames, rollout, rollout_everyother, ablate_boid_interaction)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:8\u001b[39m, in \u001b[36mnormalize_by_col\u001b[39m\u001b[34m(N, batch_num, edge_index, return_matrix)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model_names = [\"vpluspplus_a\", \"lazy\"]\n",
    "noise_levels = [0, 0.005]\n",
    "heads = [1, 2, 3]\n",
    "visual_ranges = [0.2, 0.5]\n",
    "\n",
    "all_combinations = list(product(data_names, model_name, noise_levels, heads, visual_ranges))\n",
    "\n",
    "EPOCH = 1 #20\n",
    "SEED_NUM = 5\n",
    "\n",
    "for (data_name, model_name, noise, head, visual_range) in all_combinations[:1]:\n",
    "    model_spec, train_spec = make_specs(data_name, model_name,\n",
    "                                        noise, head, visual_range, EPOCH)\n",
    "    save_name_postfix = f\"noise{noise}_head{head}_visual_range{visual_range}\"\n",
    "    \n",
    "    for seed in range(SEED_NUM):\n",
    "        loss = train(data[data_name], model_spec, train_spec, seed, save_name_postfix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3d737210-d2ca-4a64-8137-f75d4868e7ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[117]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mresult\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mtrain_losses\u001b[39m\u001b[33m\"\u001b[39m].shape\n",
      "\u001b[31mNameError\u001b[39m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "result[\"train_losses\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9b12f3ea-10cd-4c37-a5e2-4f1b6f65916e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[32m/tmp/ipykernel_13766/1118675509.py\u001b[39m(\u001b[92m37\u001b[39m)\u001b[36mtrain\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[32m     35\u001b[39m     save_model(result[\u001b[33m\"model\"\u001b[39m], model_spec, train_spec, file_name)\n",
      "\u001b[32m     36\u001b[39m \n",
      "\u001b[32m---> 37\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[32m1\u001b[39m == \u001b[32m0\u001b[39m\n",
      "\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.sum(result[\u001b[33m\"train_losses\"\u001b[39m])\n",
      "\u001b[32m     39\u001b[39m \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  np.sum(result[\"train_losses\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.float64(0.025376585848366773)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed639484-28ee-4460-bd8f-fbeb11539137",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac555a82-4835-4955-ac62-182d55209001",
   "metadata": {},
   "source": [
    "### Below needs update Aug 20, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e654a29-803c-4943-b7a3-70c2065a5be5",
   "metadata": {},
   "source": [
    "### 3. Investigate loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2f0c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_all = [models[m][\"train_losses\"] for m in [\"vpluspplus_a\"]]\n",
    "\n",
    "loss_all.append(np.tile(models[\"lazy\"][\"train_losses\"], (loss_all[0].shape[0], 1)))\n",
    "\n",
    "plot_log_loss(\n",
    "    loss_all, [m for m in models], alpha=0.05, title=\"Training loss (acceleration)\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# loss_all = [models[m][\"train_losses\"] for m in models]\n",
    "# plot_log_loss(loss_all,[m for m in models],\n",
    "#              alpha = 0.05,\n",
    "#              title = \"Training loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e7a0e9-a8f8-437a-a29a-066ce2d956fb",
   "metadata": {},
   "source": [
    "### MSE on position prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d2c9d3-3598-42ef-a2e6-84350aa4cd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: move this into a function\n",
    "loss_mse_all = {}\n",
    "for m in models:\n",
    "    loss_m = []\n",
    "    epoch_num = list(models[m][\"debug_result\"].keys())[-1]\n",
    "\n",
    "    for file_id in models[m][\"debug_result\"][epoch_num].keys():\n",
    "\n",
    "        actual = np.concatenate(\n",
    "            models[m][\"debug_result\"][epoch_num][file_id][\"actual\"], axis=0\n",
    "        )\n",
    "        predicted = np.concatenate(\n",
    "            models[m][\"debug_result\"][epoch_num][file_id][\"predicted\"], axis=0\n",
    "        )\n",
    "\n",
    "        loss = functional.mse_loss(\n",
    "            torch.tensor(actual), torch.tensor(predicted)\n",
    "        )  # + 0.1 * torch.sum(edge_weight)\n",
    "        loss_m.append(loss)\n",
    "    loss_mse_all[m] = loss_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9702b5d4-d353-4fbd-83e9-cd8e4ebc1629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all models\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "\n",
    "ind = 0\n",
    "for m in models:\n",
    "    name = m\n",
    "    mean = np.mean(loss_mse_all[m])\n",
    "    std_devs = 2 * np.std(loss_mse_all[m])\n",
    "    ax.bar(ind, mean, width=0.6)\n",
    "    ax.errorbar(ind, mean, yerr=std_devs, fmt=\"none\", color=\"black\", capsize=5)\n",
    "\n",
    "    ind += 1\n",
    "ax.set_xticks(np.arange(len(models)), labels=[m for m in models])\n",
    "ax.set_ylabel(\"Training loss (position)\")\n",
    "plt.yscale(\"log\", base=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042f4514-c1f9-49d3-8701-41713857d764",
   "metadata": {},
   "source": [
    "### To investigate one model on one file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91aa877-22d1-4908-8a94-b4fe0043f506",
   "metadata": {},
   "source": [
    "#### a) video, overlay trajectories on top of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb00c308-92cf-4d1a-a60f-68e783b38c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = 2\n",
    "epoch_num = 2\n",
    "\n",
    "m = \"vpluspplus_a\"\n",
    "rollout_debug_result = models[m][\"debug_result\"]\n",
    "actual_pos, actual_vel, actual_acc, gnn_pos, gnn_vel, gnn_acc, frame_sets = debug_result2prediction(\n",
    "                    rollout_debug_result,\n",
    "                    file_id = file_id, epoch_num = epoch_num)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cde44c-fe31-4c0f-9603-ceb5d010cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "starting_frame = 0\n",
    "ending_frame = 300\n",
    "ani, ax = visualize_graph_2sets(actual_pos[0], None, gnn_pos[0], None,\n",
    "                starting_frame = starting_frame, ending_frame = ending_frame,\n",
    "                file_id = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd4eaa2-820c-4910-9d49-8272a1ece315",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ending_frame = 50\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 5))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for b in np.arange(20):\n",
    "    if b == 0:\n",
    "        label1, label2 = \"actual\",\"predicted\"\n",
    "    else:\n",
    "        label1, label2 = None, None\n",
    "\n",
    "    ax[0].plot(actual_pos[0, starting_frame:ending_frame, b, 0] + 0.01 * b, \"+\", color = 'C0', label= label1)\n",
    "    ax[0].plot(gnn_pos[0, starting_frame:ending_frame, b, 0] + 0.01 * b, \"*\", color = 'C1',label = label2, alpha=0.5)\n",
    "    \n",
    "    \n",
    "    ax[1].plot(actual_pos[0, starting_frame:ending_frame, b, 1] + 0.01 * b, \"+\", color = 'C0', label=label1)\n",
    "    ax[1].plot(gnn_pos[0, starting_frame:ending_frame, b, 1] + 0.01 * b, \"*\", color = 'C1',label=label2, alpha=0.5)\n",
    "    \n",
    "    \n",
    "    ax[2].plot(actual_acc[0, starting_frame:ending_frame, b, 0] + 0.01 * b, color = 'C0', label=label1)\n",
    "    ax[2].plot(gnn_acc[0, starting_frame:ending_frame, b, 0] + 0.01 * b, color = 'C1',label=label2)\n",
    "    \n",
    "    \n",
    "    ax[3].plot(actual_acc[0, starting_frame:ending_frame, b, 1] + 0.01 * b, \"+\", color = 'C0', label=label1)\n",
    "    ax[3].plot(gnn_acc[0, starting_frame:ending_frame, b, 1] + 0.01 * b, color = 'C1',label=label2)\n",
    "\n",
    "    \n",
    "ax[0].set_xlabel(\"frame\")\n",
    "ax[0].set_ylabel(\"position x\")\n",
    "\n",
    "ax[1].set_xlabel(\"frame\")\n",
    "ax[1].set_ylabel(\"position y\")\n",
    "\n",
    "ax[2].set_xlabel(\"frame\")\n",
    "ax[2].set_ylabel(\"acc x\")\n",
    "\n",
    "#ax[3].plot(loss_acc, label=\"acc loss\")\n",
    "ax[3].set_xlabel(\"frame\")\n",
    "ax[3].set_ylabel(\"acc y\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb87f4d-e8c2-4313-8c4a-1e37f8562de7",
   "metadata": {},
   "source": [
    "#### b) visualize the dynamic weight matrices\n",
    "Because the attention layer is a function \n",
    "$$\n",
    "A: F \\times F \\rightarrow \\mathbb{R},\n",
    "$$\n",
    " where $F$ is the space of node feature, a subset of $\\mathbb{R}^n$, n is the dimensionality of the input layer size, we obtain dynamic adjacency matrix as boids move around producing dynamic node features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6148a5f0-c890-48c2-abed-e7c25cf2ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = \"vpluspplus_a\"\n",
    "W_output = models[m][\"W_output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c1f3fc-1944-481d-8132-fdc13cbe57ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a file\n",
    "file_id = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0ef2d0-2dda-4eb6-b005-6fdf08833f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "final_epoch = list(W_output.keys())[-1]\n",
    "W_output_overtime = W_output[final_epoch][file_id]\n",
    "frames = np.arange(0, len(W_output_overtime))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "pairs = combinations(np.arange(np.shape(W_output_overtime[0])[0]), 2)\n",
    "for p in pairs:\n",
    "    W_output_overtime_ij = [W_output_overtime[t][p[0], p[1]] for t in frames]\n",
    "    plt.plot(frames, W_output_overtime_ij)\n",
    "plt.xlabel(\"frames\")\n",
    "plt.ylabel(\"adjacency weight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf718971-d285-4157-a86e-69b1d0348d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(5, 5))\n",
    "f0 = 0\n",
    "f1 = len(W_output_overtime) - 1\n",
    "ax[0].imshow(W_output_overtime[f0])\n",
    "ax[0].set_title(f\"adjacency matrix, \\nframe {f0}\")\n",
    "ax[1].imshow(W_output_overtime[f1])\n",
    "ax[1].set_title(f\"adjacency matrix, \\nframe {f1}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b450ad-ad18-4da7-9a06-6ea9113d1313",
   "metadata": {},
   "source": [
    "## 4. Validate on held-out dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930bef3f-4130-4d20-bd51-26362b61fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "models_reload = {}\n",
    "model_spec_reload = {}\n",
    "train_spec_reload = {}\n",
    "\n",
    "for m in [\"vpluspplus_a\", \"lazy\"]:\n",
    "    file_name = f\"{data_name}_{m}_noise_{sigma}\"\n",
    "    models_reload[m] = {}\n",
    "    models_reload[m][\"model\"], model_spec_reload[m], train_spec_reload[m] = load_model(m, file_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1647028-1bfc-40be-b286-e8fc0dc61ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c63b8e4-abdd-44d6-8076-a158e3a20a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "dataloader_list = list(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2626096b-bcf5-4e02-bbfc-1634b401a069",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for m in models_reload:\n",
    "    \n",
    "    gnn_model = models_reload[m][\"model\"]\n",
    "    gnn_training_spec = train_spec_reload[m]\n",
    "\n",
    "    gnn_training_spec[\"training\"] = False\n",
    "    gnn_training_spec[\"lr\"] = None\n",
    "\n",
    "    # train models\n",
    "    (models_reload[m][\"test_losses\"], _, models_reload[m][\"test_debug_result\"]) = train_rules_gnn(\n",
    "        gnn_model,\n",
    "        test_loader,\n",
    "        species_dim=len(torch.unique(species)),\n",
    "        **gnn_training_spec\n",
    "    )\n",
    "\n",
    "    models_reload[m][\"test_W_input\"], models_reload[m][\"test_W_output\"] = get_adjcency_from_debug(\n",
    "        models_reload[m][\"test_debug_result\"], test_loader, gnn_training_spec[\"visual_range\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c802eb-ec53-48b3-aef8-a766bb8d225e",
   "metadata": {},
   "source": [
    "### Acceleration loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3bd57f-0451-49f1-bb1c-a0126e2eceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all models\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "\n",
    "ind = 0\n",
    "for m in models:\n",
    "    name = m\n",
    "    mean = np.mean(models_reload[m][\"test_losses\"])\n",
    "    std_devs = 2 * np.std(models_reload[m][\"test_losses\"])\n",
    "    ax.bar(ind, mean, width=0.6)\n",
    "    # ax.errorbar(ind, mean, yerr=std_devs, fmt=\"none\", color='black', capsize=5)\n",
    "\n",
    "    ind += 1\n",
    "ax.set_xticks(np.arange(len(models_reload)), labels=[m for m in models_reload])\n",
    "ax.set_ylabel(\"Test loss (acceleration)\")\n",
    "plt.yscale(\"log\", base=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79fe6b9-acd7-47b4-9b61-535a082d317e",
   "metadata": {},
   "source": [
    "### MSE position loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd168cb4-2e26-4f39-885f-6c9cacdacb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_mse_all = {}\n",
    "for m in models_reload:\n",
    "    loss_m = []\n",
    "    epoch_num = list(models_reload[m][\"test_debug_result\"].keys())[-1]\n",
    "\n",
    "    for file_id in models_reload[m][\"test_debug_result\"][epoch_num].keys():\n",
    "\n",
    "        actual = np.concatenate(\n",
    "            models_reload[m][\"test_debug_result\"][epoch_num][file_id][\"actual\"], axis=0\n",
    "        )\n",
    "        predicted = np.concatenate(\n",
    "            models_reload[m][\"test_debug_result\"][epoch_num][file_id][\"predicted\"], axis=0\n",
    "        )\n",
    "\n",
    "        loss = functional.mse_loss(\n",
    "            torch.tensor(actual), torch.tensor(predicted)\n",
    "        )  # + 0.1 * torch.sum(edge_weight)\n",
    "        loss_m.append(loss)\n",
    "    test_loss_mse_all[m] = loss_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e35cf51-7f56-417b-8b92-16c62c6787a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all models\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "\n",
    "ind = 0\n",
    "for m in models_reload:\n",
    "    name = m\n",
    "    mean = np.mean(test_loss_mse_all[m])\n",
    "    std_devs = 2 * np.std(test_loss_mse_all[m])\n",
    "    ax.bar(ind, mean, width=0.6)\n",
    "    # ax.errorbar(ind, mean, yerr=std_devs, fmt=\"none\", color='black', capsize=5)\n",
    "\n",
    "    ind += 1\n",
    "ax.set_xticks(np.arange(len(models_reload)), labels=[m for m in models_reload])\n",
    "ax.set_ylabel(\"Test loss (position)\")\n",
    "plt.yscale(\"log\", base=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ba7d35-5b77-4cee-bf00-1cbcff7d0c3d",
   "metadata": {},
   "source": [
    "### plot all birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bf159c-5480-4900-a7da-cc9bbf1c8922",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = 8\n",
    "\n",
    "m = \"vpluspplus_a\"\n",
    "rollout_debug_result = models_reload[m][\"test_debug_result\"]\n",
    "actual_pos, actual_vel, actual_acc, gnn_pos, gnn_vel, gnn_acc, frame_sets = debug_result2prediction(\n",
    "                    rollout_debug_result,\n",
    "                    file_id = file_id, epoch_num = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37bc599-c5c1-434a-ac51-1be5e1b6e7db",
   "metadata": {},
   "source": [
    "## 5. Rollout on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834503d4-99d1-4229-b387-9c2badf25017",
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout = 5 #the frame to start rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5e4d45-f7ba-48cd-95c3-20a1b01b644e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "for m in [\"vpluspplus_a\"]:\n",
    "    \n",
    "    gnn_model = models_reload[m][\"model\"]\n",
    "    gnn_training_spec = train_spec_reload[m]\n",
    "\n",
    "    gnn_training_spec[\"training\"] = False\n",
    "    gnn_training_spec[\"lr\"] = None\n",
    "    gnn_training_spec[\"rollout\"] = rollout\n",
    "\n",
    "    # train models\n",
    "    (models_reload[m][\"rollout_losses\"], _, models_reload[m][\"rollout_debug_result\"]) = train_rules_gnn(\n",
    "        gnn_model,\n",
    "        test_loader,\n",
    "        species_dim=len(torch.unique(species)),\n",
    "        **gnn_training_spec\n",
    "    )\n",
    "\n",
    "    models_reload[m][\"rollout_W_input\"], models_reload[m][\"rollout_W_output\"] = get_adjcency_from_debug(\n",
    "        models_reload[m][\"rollout_debug_result\"], test_loader, gnn_training_spec[\"visual_range\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d33da54-7ad5-4090-ab7e-21cb07b5c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = 9\n",
    "\n",
    "m = \"vpluspplus_a\"\n",
    "rollout_debug_result = models_reload[m][\"rollout_debug_result\"]\n",
    "actual_pos, actual_vel, actual_acc, gnn_pos, gnn_vel, gnn_acc, frame_sets = debug_result2prediction(\n",
    "                    rollout_debug_result,\n",
    "                    file_id = file_id, epoch_num = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56b6f41-7b8a-4174-a123-9b8549187fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "starting_frame = 0\n",
    "ending_frame = 300\n",
    "ani, ax = visualize_graph_2sets(actual_pos[0], actual_vel[0], gnn_pos[0], gnn_vel[0],\n",
    "                starting_frame = starting_frame, ending_frame = ending_frame,\n",
    "                file_id = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b937f983-5ec3-4293-97dd-e7031655dda4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
