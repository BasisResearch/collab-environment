{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cd895be-ab28-49e9-9581-ffbb3513a3a6",
   "metadata": {},
   "source": [
    "# Basic demo of training GNN on boid model.\n",
    "All the scripts are in **scripts.gnn.gnn** and **scripts.gnn.gnn_definition**.\n",
    "The scripts build barebone GNN network architecture, handling of discrete data. \n",
    "The notebook illustrates training and testing and demos of single-frame prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdefeac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e23875c-81f4-4658-babe-f687072f7d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "\n",
    "# script_path = os.path.realpath(os.path.dirname(__name__))\n",
    "# os.chdir(script_path)\n",
    "# sys.path.append(\"/workspace/collab-environment/\")\n",
    "# sys.path.append(\"/workspace/collab-environment/collab_env/gnn\")\n",
    "# sys.path.append(\"/workspace/collab-environment/collab_env/data/boids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1451bcb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from typing import Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as functional\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from collab_env.data.file_utils import expand_path, get_project_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cad07db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collab_env.gnn.gnn import get_adjcency_from_debug, plot_log_loss, train_rules_gnn, load_model, save_model, debug_result2prediction\n",
    "from collab_env.gnn.gnn_definition import GNN, Lazy\n",
    "from collab_env.data.boids.animal_simulation import visualize_graph_2sets\n",
    "from collab_env.gnn.utility import dataset2testloader\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d34783",
   "metadata": {},
   "source": [
    "### 1. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f1d272-4a0a-4500-9a97-b1ddddf36513",
   "metadata": {},
   "source": [
    "#### (A) Boid with boundary\n",
    "#### (B) Independent with boundary\n",
    "#### (C) Boid with boundary and food\n",
    "#### (D) Independent with boundary and food\n",
    "#### (E) Boid with boundary and strong influence food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2599830c-3e1f-430d-b6e6-6249921eac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_names = ['boid_single_species_basic', 'boid_single_species_independent', # without food\n",
    "              'boid_food_basic', 'boid_food_medium_independent', # with food\n",
    "              'boid_food_strong'] # with food, strong influence\n",
    "\n",
    "batch_size = 100\n",
    "data = {}\n",
    "\n",
    "for data_name in data_names:\n",
    "    file_name = f'{data_name}.pt'\n",
    "    config_name = f'{data_name}_config.pt'\n",
    "    \n",
    "    dataset = torch.load(expand_path(\n",
    "            \"simulated_data/\" + file_name, get_project_root()), weights_only = False)\n",
    "    species_configs = torch.load(expand_path(\n",
    "            \"simulated_data/\" + config_name, get_project_root()), weights_only = False)\n",
    "\n",
    "    test_loader, train_loader = dataset2testloader(dataset, batch_size = batch_size,\n",
    "                                                   return_train = True)\n",
    "\n",
    "    data[data_name] = {}\n",
    "    data[data_name][\"data_name\"] = data_name\n",
    "    data[data_name][\"file_name\"] = file_name\n",
    "    data[data_name][\"config_name\"] = config_name\n",
    "    data[data_name][\"dataset\"] = dataset\n",
    "    data[data_name][\"species_configs\"] = species_configs\n",
    "    data[data_name]['test_loader'] = test_loader\n",
    "    data[data_name]['train_loader'] = train_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c034e2-d4a0-416a-8b97-9e9335524dd7",
   "metadata": {},
   "source": [
    "### 2. Train GNN and our lazyGNN\n",
    "The lazy model only outputs a zero acceleration at all frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57305ffe-962e-4207-b15f-4442d98ad46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_specs(data_name, model_name, batch_size,\n",
    "               noise_level, head, visual_range, epoch):\n",
    "    \"\"\"\n",
    "    data_name: name of the dataset\n",
    "    model_name: name of th\n",
    "    \"\"\"\n",
    "\n",
    "    if \"food\" in data_name:\n",
    "        in_node_dim = 20\n",
    "    else:\n",
    "        in_node_dim = 19\n",
    "\n",
    "    if \"lazy\" in model_name:\n",
    "        model_spec_lazy = {\n",
    "            \"model_name\": \"lazy\",\n",
    "            \"prediction_integration\": \"Euler\",  # predict model acceleration\n",
    "            \"input_differentiation\":\"finite\",\n",
    "            \"in_node_dim\": 3,\n",
    "            \"start_frame\": 3,\n",
    "            \"heads\": 1}\n",
    "\n",
    "        train_spec_lazy = {\n",
    "            \"lr\": None,\n",
    "            \"visual_range\": visual_range,\n",
    "            \"sigma\": sigma,\n",
    "            \"epochs\": 1}\n",
    "        \n",
    "        return model_spec_gnn, train_spec_gnn\n",
    "    \n",
    "    model_spec_gnn = {\n",
    "        \"model_name\": \"vpluspplus_a\",\n",
    "        \"node_feature_function\": \"vel_plus_pos_plus\",  # features are velocity(t-2), velocity(t-1), velocity(t)\n",
    "        \"node_prediction\": \"acc\",  # predict model acceleration\n",
    "        \"prediction_integration\": \"Euler\",  # predict model acceleration\n",
    "        \"input_differentiation\": \"finite\",\n",
    "        \"in_node_dim\": in_node_dim,\n",
    "        \"start_frame\": 3,\n",
    "        \"heads\": head\n",
    "    }\n",
    "\n",
    "    train_spec_gnn = {\n",
    "        \"lr\": 1e-4,\n",
    "        \"visual_range\": visual_range,\n",
    "        \"epochs\": epoch,\n",
    "        \"sigma\": noise_level,\n",
    "        \"training\": True\n",
    "    }\n",
    "    \n",
    "    return model_spec_gnn, train_spec_gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b031825c-acbc-491e-b85a-696a978ede53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_models(model_name, model_spec, train_spec):\n",
    "    gnn_model: torch.nn.Module | None = None\n",
    "        \n",
    "    # initialize models\n",
    "    if \"lazy\" in model_name:\n",
    "        training = False\n",
    "        gnn_model = Lazy(\n",
    "            **model_spec\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        training = True\n",
    "        gnn_model = GNN(\n",
    "            **model_spec\n",
    "        )\n",
    "\n",
    "    train_spec[\"training\"] = training\n",
    "\n",
    "    return gnn_model, train_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeafe19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(data, model_spec, train_spec, seed, save_name_postfix):\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.manual_seed(seed)  # PyTorch CPU and CUDA\n",
    "\n",
    "    m = model_spec[\"model_name\"]\n",
    "        \n",
    "    result = {}\n",
    "    \n",
    "    gnn_model, train_spec = initialize_models(m, model_spec, train_spec)\n",
    "    \n",
    "    # data\n",
    "    data_name = data['data_name']\n",
    "    train_loader = data['train_loader']\n",
    "    species_dim = len(data['species_configs'].keys())\n",
    "        \n",
    "    \n",
    "    # train models\n",
    "    (result[\"train_losses\"], result[\"model\"], result[\"debug_result\"]) = (\n",
    "        train_rules_gnn(\n",
    "            gnn_model,\n",
    "            train_loader,\n",
    "            species_dim = species_dim,\n",
    "            **train_spec\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    #models[m][\"W_input\"], models[m][\"W_output\"] = get_adjcency_from_debug(\n",
    "    #    models[m][\"debug_result\"], train_loader, visual_range\n",
    "    #)\n",
    "\n",
    "    gnn_model = result[\"model\"]\n",
    "    noise_level = train_spec[\"sigma\"]\n",
    "        \n",
    "    file_name = f\"{data_name}_{m}_{save_name_postfix}_seed{seed}\"\n",
    "    save_model(gnn_model, model_spec, train_spec, file_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c834b2b-65a9-47c8-8e62-8f134b472162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boid_single_species_basic',\n",
       " 'boid_single_species_independent',\n",
       " 'boid_food_basic',\n",
       " 'boid_food_medium_independent',\n",
       " 'boid_food_strong']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c634751-2d2c-4c4a-9733-d5fa04052e30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-23 12:18:29.698\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcollab_env.gnn.gnn\u001b[0m:\u001b[36mtrain_rules_gnn\u001b[0m:\u001b[36m600\u001b[0m - \u001b[34m\u001b[1mStarting epoch 1/2\u001b[0m\n",
      "\u001b[32m2025-08-23 12:18:29.704\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcollab_env.gnn.gnn\u001b[0m:\u001b[36mtrain_rules_gnn\u001b[0m:\u001b[36m608\u001b[0m - \u001b[34m\u001b[1mEpoch 1/2 | Processing batch 1/7\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training boid_single_species_basic with vpluspplus_a with 0 noise, 1 heads, 0.5 visual range\n",
      "Training boid_single_species_basic with vpluspplus_a with 0 noise, 1 heads, 0.5 visual range, seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-23 12:18:57.974\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcollab_env.gnn.gnn\u001b[0m:\u001b[36mtrain_rules_gnn\u001b[0m:\u001b[36m608\u001b[0m - \u001b[34m\u001b[1mEpoch 1/2 | Processing batch 2/7\u001b[0m\n",
      "\u001b[32m2025-08-23 12:19:25.002\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcollab_env.gnn.gnn\u001b[0m:\u001b[36mtrain_rules_gnn\u001b[0m:\u001b[36m608\u001b[0m - \u001b[34m\u001b[1mEpoch 1/2 | Processing batch 3/7\u001b[0m\n",
      "\u001b[32m2025-08-23 12:19:52.273\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcollab_env.gnn.gnn\u001b[0m:\u001b[36mtrain_rules_gnn\u001b[0m:\u001b[36m608\u001b[0m - \u001b[34m\u001b[1mEpoch 1/2 | Processing batch 4/7\u001b[0m\n",
      "\u001b[32m2025-08-23 12:20:19.620\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcollab_env.gnn.gnn\u001b[0m:\u001b[36mtrain_rules_gnn\u001b[0m:\u001b[36m608\u001b[0m - \u001b[34m\u001b[1mEpoch 1/2 | Processing batch 5/7\u001b[0m\n",
      "\u001b[32m2025-08-23 12:20:47.164\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcollab_env.gnn.gnn\u001b[0m:\u001b[36mtrain_rules_gnn\u001b[0m:\u001b[36m608\u001b[0m - \u001b[34m\u001b[1mEpoch 1/2 | Processing batch 6/7\u001b[0m\n",
      "\u001b[32m2025-08-23 12:21:14.523\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcollab_env.gnn.gnn\u001b[0m:\u001b[36mtrain_rules_gnn\u001b[0m:\u001b[36m608\u001b[0m - \u001b[34m\u001b[1mEpoch 1/2 | Processing batch 7/7\u001b[0m\n",
      "\u001b[32m2025-08-23 12:21:41.858\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcollab_env.gnn.gnn\u001b[0m:\u001b[36mtrain_rules_gnn\u001b[0m:\u001b[36m632\u001b[0m - \u001b[34m\u001b[1mEpoch 000 | Train loss: 0.0008388\u001b[0m\n",
      "\u001b[32m2025-08-23 12:21:41.859\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcollab_env.gnn.gnn\u001b[0m:\u001b[36mtrain_rules_gnn\u001b[0m:\u001b[36m600\u001b[0m - \u001b[34m\u001b[1mStarting epoch 2/2\u001b[0m\n",
      "\u001b[32m2025-08-23 12:21:41.863\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcollab_env.gnn.gnn\u001b[0m:\u001b[36mtrain_rules_gnn\u001b[0m:\u001b[36m608\u001b[0m - \u001b[34m\u001b[1mEpoch 2/2 | Processing batch 1/7\u001b[0m\n",
      "\u001b[32m2025-08-23 12:22:10.214\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcollab_env.gnn.gnn\u001b[0m:\u001b[36mtrain_rules_gnn\u001b[0m:\u001b[36m608\u001b[0m - \u001b[34m\u001b[1mEpoch 2/2 | Processing batch 2/7\u001b[0m\n",
      "\u001b[32m2025-08-23 12:22:38.068\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcollab_env.gnn.gnn\u001b[0m:\u001b[36mtrain_rules_gnn\u001b[0m:\u001b[36m608\u001b[0m - \u001b[34m\u001b[1mEpoch 2/2 | Processing batch 3/7\u001b[0m\n",
      "\u001b[32m2025-08-23 12:23:05.355\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcollab_env.gnn.gnn\u001b[0m:\u001b[36mtrain_rules_gnn\u001b[0m:\u001b[36m608\u001b[0m - \u001b[34m\u001b[1mEpoch 2/2 | Processing batch 4/7\u001b[0m\n",
      "\u001b[32m2025-08-23 12:23:33.889\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcollab_env.gnn.gnn\u001b[0m:\u001b[36mtrain_rules_gnn\u001b[0m:\u001b[36m608\u001b[0m - \u001b[34m\u001b[1mEpoch 2/2 | Processing batch 5/7\u001b[0m\n",
      "\u001b[32m2025-08-23 12:24:08.112\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcollab_env.gnn.gnn\u001b[0m:\u001b[36mtrain_rules_gnn\u001b[0m:\u001b[36m608\u001b[0m - \u001b[34m\u001b[1mEpoch 2/2 | Processing batch 6/7\u001b[0m\n",
      "\u001b[32m2025-08-23 12:24:43.593\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcollab_env.gnn.gnn\u001b[0m:\u001b[36mtrain_rules_gnn\u001b[0m:\u001b[36m608\u001b[0m - \u001b[34m\u001b[1mEpoch 2/2 | Processing batch 7/7\u001b[0m\n",
      "\u001b[32m2025-08-23 12:25:18.543\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcollab_env.gnn.gnn\u001b[0m:\u001b[36mtrain_rules_gnn\u001b[0m:\u001b[36m632\u001b[0m - \u001b[34m\u001b[1mEpoch 001 | Train loss: 0.0003512\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_names = [\"vpluspplus_a\"]\n",
    "noise_levels = [0]\n",
    "heads = [1]\n",
    "visual_ranges = [0.5]\n",
    "\n",
    "all_combinations = list(product(data_names, model_names, noise_levels, heads, visual_ranges))\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "EPOCH = 2\n",
    "SEED_NUM = 1\n",
    "\n",
    "for (data_name, model_name, noise, head, visual_range) in all_combinations[:1]:\n",
    "    model_spec, train_spec = make_specs(data_name, model_name,\n",
    "                                                BATCH_SIZE,\n",
    "                                                noise, head, visual_range, EPOCH)\n",
    "    save_name_postfix = f\"noise{noise}_head{head}_visual_range{visual_range}\"\n",
    "    print(f\"Training {data_name} with {model_name} with {noise} noise, {head} heads, {visual_range} visual range\")\n",
    "    for seed in range(SEED_NUM):\n",
    "        print(f\"Training {data_name} with {model_name} with {noise} noise, {head} heads, {visual_range} visual range, seed {seed}\")\n",
    "        train(data[data_name], model_spec, train_spec, seed, save_name_postfix)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac555a82-4835-4955-ac62-182d55209001",
   "metadata": {},
   "source": [
    "### Below needs update Aug 20, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e654a29-803c-4943-b7a3-70c2065a5be5",
   "metadata": {},
   "source": [
    "### 3. Investigate loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2f0c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_all = [models[m][\"train_losses\"] for m in [\"vpluspplus_a\"]]\n",
    "\n",
    "loss_all.append(np.tile(models[\"lazy\"][\"train_losses\"], (loss_all[0].shape[0], 1)))\n",
    "\n",
    "plot_log_loss(\n",
    "    loss_all, [m for m in models], alpha=0.05, title=\"Training loss (acceleration)\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# loss_all = [models[m][\"train_losses\"] for m in models]\n",
    "# plot_log_loss(loss_all,[m for m in models],\n",
    "#              alpha = 0.05,\n",
    "#              title = \"Training loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e7a0e9-a8f8-437a-a29a-066ce2d956fb",
   "metadata": {},
   "source": [
    "### MSE on position prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d2c9d3-3598-42ef-a2e6-84350aa4cd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: move this into a function\n",
    "loss_mse_all = {}\n",
    "for m in models:\n",
    "    loss_m = []\n",
    "    epoch_num = list(models[m][\"debug_result\"].keys())[-1]\n",
    "\n",
    "    for file_id in models[m][\"debug_result\"][epoch_num].keys():\n",
    "\n",
    "        actual = np.concatenate(\n",
    "            models[m][\"debug_result\"][epoch_num][file_id][\"actual\"], axis=0\n",
    "        )\n",
    "        predicted = np.concatenate(\n",
    "            models[m][\"debug_result\"][epoch_num][file_id][\"predicted\"], axis=0\n",
    "        )\n",
    "\n",
    "        loss = functional.mse_loss(\n",
    "            torch.tensor(actual), torch.tensor(predicted)\n",
    "        )  # + 0.1 * torch.sum(edge_weight)\n",
    "        loss_m.append(loss)\n",
    "    loss_mse_all[m] = loss_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9702b5d4-d353-4fbd-83e9-cd8e4ebc1629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all models\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "\n",
    "ind = 0\n",
    "for m in models:\n",
    "    name = m\n",
    "    mean = np.mean(loss_mse_all[m])\n",
    "    std_devs = 2 * np.std(loss_mse_all[m])\n",
    "    ax.bar(ind, mean, width=0.6)\n",
    "    ax.errorbar(ind, mean, yerr=std_devs, fmt=\"none\", color=\"black\", capsize=5)\n",
    "\n",
    "    ind += 1\n",
    "ax.set_xticks(np.arange(len(models)), labels=[m for m in models])\n",
    "ax.set_ylabel(\"Training loss (position)\")\n",
    "plt.yscale(\"log\", base=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042f4514-c1f9-49d3-8701-41713857d764",
   "metadata": {},
   "source": [
    "### To investigate one model on one file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91aa877-22d1-4908-8a94-b4fe0043f506",
   "metadata": {},
   "source": [
    "#### a) video, overlay trajectories on top of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb00c308-92cf-4d1a-a60f-68e783b38c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = 2\n",
    "epoch_num = 2\n",
    "\n",
    "m = \"vpluspplus_a\"\n",
    "rollout_debug_result = models[m][\"debug_result\"]\n",
    "actual_pos, actual_vel, actual_acc, gnn_pos, gnn_vel, gnn_acc, frame_sets = debug_result2prediction(\n",
    "                    rollout_debug_result,\n",
    "                    file_id = file_id, epoch_num = epoch_num)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cde44c-fe31-4c0f-9603-ceb5d010cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "starting_frame = 0\n",
    "ending_frame = 300\n",
    "ani, ax = visualize_graph_2sets(actual_pos[0], None, gnn_pos[0], None,\n",
    "                starting_frame = starting_frame, ending_frame = ending_frame,\n",
    "                file_id = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd4eaa2-820c-4910-9d49-8272a1ece315",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ending_frame = 50\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 5))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for b in np.arange(20):\n",
    "    if b == 0:\n",
    "        label1, label2 = \"actual\",\"predicted\"\n",
    "    else:\n",
    "        label1, label2 = None, None\n",
    "\n",
    "    ax[0].plot(actual_pos[0, starting_frame:ending_frame, b, 0] + 0.01 * b, \"+\", color = 'C0', label= label1)\n",
    "    ax[0].plot(gnn_pos[0, starting_frame:ending_frame, b, 0] + 0.01 * b, \"*\", color = 'C1',label = label2, alpha=0.5)\n",
    "    \n",
    "    \n",
    "    ax[1].plot(actual_pos[0, starting_frame:ending_frame, b, 1] + 0.01 * b, \"+\", color = 'C0', label=label1)\n",
    "    ax[1].plot(gnn_pos[0, starting_frame:ending_frame, b, 1] + 0.01 * b, \"*\", color = 'C1',label=label2, alpha=0.5)\n",
    "    \n",
    "    \n",
    "    ax[2].plot(actual_acc[0, starting_frame:ending_frame, b, 0] + 0.01 * b, color = 'C0', label=label1)\n",
    "    ax[2].plot(gnn_acc[0, starting_frame:ending_frame, b, 0] + 0.01 * b, color = 'C1',label=label2)\n",
    "    \n",
    "    \n",
    "    ax[3].plot(actual_acc[0, starting_frame:ending_frame, b, 1] + 0.01 * b, \"+\", color = 'C0', label=label1)\n",
    "    ax[3].plot(gnn_acc[0, starting_frame:ending_frame, b, 1] + 0.01 * b, color = 'C1',label=label2)\n",
    "\n",
    "    \n",
    "ax[0].set_xlabel(\"frame\")\n",
    "ax[0].set_ylabel(\"position x\")\n",
    "\n",
    "ax[1].set_xlabel(\"frame\")\n",
    "ax[1].set_ylabel(\"position y\")\n",
    "\n",
    "ax[2].set_xlabel(\"frame\")\n",
    "ax[2].set_ylabel(\"acc x\")\n",
    "\n",
    "#ax[3].plot(loss_acc, label=\"acc loss\")\n",
    "ax[3].set_xlabel(\"frame\")\n",
    "ax[3].set_ylabel(\"acc y\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb87f4d-e8c2-4313-8c4a-1e37f8562de7",
   "metadata": {},
   "source": [
    "#### b) visualize the dynamic weight matrices\n",
    "Because the attention layer is a function \n",
    "$$\n",
    "A: F \\times F \\rightarrow \\mathbb{R},\n",
    "$$\n",
    " where $F$ is the space of node feature, a subset of $\\mathbb{R}^n$, n is the dimensionality of the input layer size, we obtain dynamic adjacency matrix as boids move around producing dynamic node features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6148a5f0-c890-48c2-abed-e7c25cf2ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = \"vpluspplus_a\"\n",
    "W_output = models[m][\"W_output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c1f3fc-1944-481d-8132-fdc13cbe57ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a file\n",
    "file_id = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0ef2d0-2dda-4eb6-b005-6fdf08833f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "final_epoch = list(W_output.keys())[-1]\n",
    "W_output_overtime = W_output[final_epoch][file_id]\n",
    "frames = np.arange(0, len(W_output_overtime))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "pairs = combinations(np.arange(np.shape(W_output_overtime[0])[0]), 2)\n",
    "for p in pairs:\n",
    "    W_output_overtime_ij = [W_output_overtime[t][p[0], p[1]] for t in frames]\n",
    "    plt.plot(frames, W_output_overtime_ij)\n",
    "plt.xlabel(\"frames\")\n",
    "plt.ylabel(\"adjacency weight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf718971-d285-4157-a86e-69b1d0348d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(5, 5))\n",
    "f0 = 0\n",
    "f1 = len(W_output_overtime) - 1\n",
    "ax[0].imshow(W_output_overtime[f0])\n",
    "ax[0].set_title(f\"adjacency matrix, \\nframe {f0}\")\n",
    "ax[1].imshow(W_output_overtime[f1])\n",
    "ax[1].set_title(f\"adjacency matrix, \\nframe {f1}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b450ad-ad18-4da7-9a06-6ea9113d1313",
   "metadata": {},
   "source": [
    "## 4. Validate on held-out dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930bef3f-4130-4d20-bd51-26362b61fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "models_reload = {}\n",
    "model_spec_reload = {}\n",
    "train_spec_reload = {}\n",
    "\n",
    "for m in [\"vpluspplus_a\", \"lazy\"]:\n",
    "    file_name = f\"{data_name}_{m}_noise_{sigma}\"\n",
    "    models_reload[m] = {}\n",
    "    models_reload[m][\"model\"], model_spec_reload[m], train_spec_reload[m] = load_model(m, file_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1647028-1bfc-40be-b286-e8fc0dc61ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c63b8e4-abdd-44d6-8076-a158e3a20a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "dataloader_list = list(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2626096b-bcf5-4e02-bbfc-1634b401a069",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for m in models_reload:\n",
    "    \n",
    "    gnn_model = models_reload[m][\"model\"]\n",
    "    gnn_training_spec = train_spec_reload[m]\n",
    "\n",
    "    gnn_training_spec[\"training\"] = False\n",
    "    gnn_training_spec[\"lr\"] = None\n",
    "\n",
    "    # train models\n",
    "    (models_reload[m][\"test_losses\"], _, models_reload[m][\"test_debug_result\"]) = train_rules_gnn(\n",
    "        gnn_model,\n",
    "        test_loader,\n",
    "        species_dim=len(torch.unique(species)),\n",
    "        **gnn_training_spec\n",
    "    )\n",
    "\n",
    "    models_reload[m][\"test_W_input\"], models_reload[m][\"test_W_output\"] = get_adjcency_from_debug(\n",
    "        models_reload[m][\"test_debug_result\"], test_loader, gnn_training_spec[\"visual_range\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c802eb-ec53-48b3-aef8-a766bb8d225e",
   "metadata": {},
   "source": [
    "### Acceleration loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3bd57f-0451-49f1-bb1c-a0126e2eceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all models\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "\n",
    "ind = 0\n",
    "for m in models:\n",
    "    name = m\n",
    "    mean = np.mean(models_reload[m][\"test_losses\"])\n",
    "    std_devs = 2 * np.std(models_reload[m][\"test_losses\"])\n",
    "    ax.bar(ind, mean, width=0.6)\n",
    "    # ax.errorbar(ind, mean, yerr=std_devs, fmt=\"none\", color='black', capsize=5)\n",
    "\n",
    "    ind += 1\n",
    "ax.set_xticks(np.arange(len(models_reload)), labels=[m for m in models_reload])\n",
    "ax.set_ylabel(\"Test loss (acceleration)\")\n",
    "plt.yscale(\"log\", base=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79fe6b9-acd7-47b4-9b61-535a082d317e",
   "metadata": {},
   "source": [
    "### MSE position loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd168cb4-2e26-4f39-885f-6c9cacdacb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_mse_all = {}\n",
    "for m in models_reload:\n",
    "    loss_m = []\n",
    "    epoch_num = list(models_reload[m][\"test_debug_result\"].keys())[-1]\n",
    "\n",
    "    for file_id in models_reload[m][\"test_debug_result\"][epoch_num].keys():\n",
    "\n",
    "        actual = np.concatenate(\n",
    "            models_reload[m][\"test_debug_result\"][epoch_num][file_id][\"actual\"], axis=0\n",
    "        )\n",
    "        predicted = np.concatenate(\n",
    "            models_reload[m][\"test_debug_result\"][epoch_num][file_id][\"predicted\"], axis=0\n",
    "        )\n",
    "\n",
    "        loss = functional.mse_loss(\n",
    "            torch.tensor(actual), torch.tensor(predicted)\n",
    "        )  # + 0.1 * torch.sum(edge_weight)\n",
    "        loss_m.append(loss)\n",
    "    test_loss_mse_all[m] = loss_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e35cf51-7f56-417b-8b92-16c62c6787a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all models\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "\n",
    "ind = 0\n",
    "for m in models_reload:\n",
    "    name = m\n",
    "    mean = np.mean(test_loss_mse_all[m])\n",
    "    std_devs = 2 * np.std(test_loss_mse_all[m])\n",
    "    ax.bar(ind, mean, width=0.6)\n",
    "    # ax.errorbar(ind, mean, yerr=std_devs, fmt=\"none\", color='black', capsize=5)\n",
    "\n",
    "    ind += 1\n",
    "ax.set_xticks(np.arange(len(models_reload)), labels=[m for m in models_reload])\n",
    "ax.set_ylabel(\"Test loss (position)\")\n",
    "plt.yscale(\"log\", base=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ba7d35-5b77-4cee-bf00-1cbcff7d0c3d",
   "metadata": {},
   "source": [
    "### plot all birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bf159c-5480-4900-a7da-cc9bbf1c8922",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = 8\n",
    "\n",
    "m = \"vpluspplus_a\"\n",
    "rollout_debug_result = models_reload[m][\"test_debug_result\"]\n",
    "actual_pos, actual_vel, actual_acc, gnn_pos, gnn_vel, gnn_acc, frame_sets = debug_result2prediction(\n",
    "                    rollout_debug_result,\n",
    "                    file_id = file_id, epoch_num = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37bc599-c5c1-434a-ac51-1be5e1b6e7db",
   "metadata": {},
   "source": [
    "## 5. Rollout on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834503d4-99d1-4229-b387-9c2badf25017",
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout = 5 #the frame to start rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5e4d45-f7ba-48cd-95c3-20a1b01b644e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "for m in [\"vpluspplus_a\"]:\n",
    "    \n",
    "    gnn_model = models_reload[m][\"model\"]\n",
    "    gnn_training_spec = train_spec_reload[m]\n",
    "\n",
    "    gnn_training_spec[\"training\"] = False\n",
    "    gnn_training_spec[\"lr\"] = None\n",
    "    gnn_training_spec[\"rollout\"] = rollout\n",
    "\n",
    "    # train models\n",
    "    (models_reload[m][\"rollout_losses\"], _, models_reload[m][\"rollout_debug_result\"]) = train_rules_gnn(\n",
    "        gnn_model,\n",
    "        test_loader,\n",
    "        species_dim=len(torch.unique(species)),\n",
    "        **gnn_training_spec\n",
    "    )\n",
    "\n",
    "    models_reload[m][\"rollout_W_input\"], models_reload[m][\"rollout_W_output\"] = get_adjcency_from_debug(\n",
    "        models_reload[m][\"rollout_debug_result\"], test_loader, gnn_training_spec[\"visual_range\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d33da54-7ad5-4090-ab7e-21cb07b5c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = 9\n",
    "\n",
    "m = \"vpluspplus_a\"\n",
    "rollout_debug_result = models_reload[m][\"rollout_debug_result\"]\n",
    "actual_pos, actual_vel, actual_acc, gnn_pos, gnn_vel, gnn_acc, frame_sets = debug_result2prediction(\n",
    "                    rollout_debug_result,\n",
    "                    file_id = file_id, epoch_num = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56b6f41-7b8a-4174-a123-9b8549187fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "starting_frame = 0\n",
    "ending_frame = 300\n",
    "ani, ax = visualize_graph_2sets(actual_pos[0], actual_vel[0], gnn_pos[0], gnn_vel[0],\n",
    "                starting_frame = starting_frame, ending_frame = ending_frame,\n",
    "                file_id = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b937f983-5ec3-4293-97dd-e7031655dda4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
