{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f61ee5f",
   "metadata": {},
   "source": [
    "# Reprojection of tracks to 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e03ba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyvista as pv\n",
    "from matplotlib.pyplot import cm\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collab_env.alignment import reprojection\n",
    "from collab_env.data.file_utils import get_project_root\n",
    "from collab_env.utils import visualization as viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ab8a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b300367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f9e58",
   "metadata": {},
   "source": [
    "### Get info from GCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb99e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"fieldwork_processed\"\n",
    "session = \"2024_02_06-session_0001\"\n",
    "splat_video = \"C0043\"\n",
    "camera_id = \"rgb_1\"\n",
    "\n",
    "# Make the session directory\n",
    "session_data_dir = get_project_root() / \"data\" / data_type / session\n",
    "\n",
    "# Requirements for alignment\n",
    "environment_dir = session_data_dir / \"environment\"\n",
    "aligned_frames_dir = session_data_dir / \"aligned_frames\" / camera_id\n",
    "aligned_splat_dir = session_data_dir / \"aligned_splat\" / camera_id\n",
    "\n",
    "# Files for reprojection\n",
    "mesh_fn = environment_dir / splat_video / \"rade-features\" / \"mesh\" / \"mesh.ply\"\n",
    "aligned_camera_fn = aligned_splat_dir / f\"{camera_id}_mesh-aligned.pkl\"\n",
    "tracking_fn = aligned_frames_dir / f\"{camera_id}_tracked_bboxes.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460d94fa",
   "metadata": {},
   "source": [
    "Load the required files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9954d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracks over the 2d video\n",
    "df_tracks = pd.read_csv(tracking_fn)\n",
    "df_tracks[\"track_id\"] = df_tracks[\"track_id\"].astype(int)\n",
    "\n",
    "# Camera aligned to the mesh\n",
    "with open(aligned_camera_fn, \"rb\") as f:\n",
    "    camera_params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb99165",
   "metadata": {},
   "source": [
    "### Create reprojection objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432183b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the camera to reproject from\n",
    "camera = reprojection.Camera(\n",
    "    K=camera_params[\"K\"],\n",
    "    c2w=camera_params[\"c2w\"],\n",
    "    width=camera_params[\"width\"],\n",
    "    height=camera_params[\"height\"],\n",
    ")\n",
    "\n",
    "# Create the mesh to reproject to\n",
    "mesh_environment = reprojection.MeshEnvironment(mesh_fn)\n",
    "\n",
    "# Render the camera view of the mesh --> updates camera.image and camera.depth\n",
    "image, depth = mesh_environment.render_camera(camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89cf2ae",
   "metadata": {},
   "source": [
    "Visualize camera view of the mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d1962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the image and depth\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "axs[0].imshow(image)\n",
    "axs[0].set_title(\"Image\")\n",
    "axs[0].axis(\"off\")\n",
    "\n",
    "axs[1].imshow(depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998af56c",
   "metadata": {},
   "source": [
    "### Visualize depth on mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5718f381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our camera and mesh environment to create an array of points on the mesh\n",
    "mesh_depths = reprojection.get_depths_on_mesh(\n",
    "    camera=camera, mesh=mesh_environment.mesh, smooth=True, radius=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c0490c",
   "metadata": {},
   "source": [
    "Use visualization tools to view the projected depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480d406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mesh as a pyvista object\n",
    "pv_mesh = pv.read(mesh_fn)\n",
    "\n",
    "# Convert to RGB via colormap\n",
    "depth_rgb = cm.get_cmap(\"viridis\")(mesh_depths)\n",
    "depth_rgb[np.isnan(mesh_depths)] = [0, 0, 0, 1]\n",
    "\n",
    "# Set as an attribute of the mesh\n",
    "pv_mesh.point_data[\"depths\"] = depth_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333f0079",
   "metadata": {},
   "source": [
    "Make a nice plot of depths visualized on the mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e20cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy our camera parameters and format for pyvista\n",
    "# TLB --> NEED TO FIX, IDK WHY IT INTERNALLY ALTERS PV_CAMERA\n",
    "pv_camera = deepcopy(camera_params)\n",
    "_ = viz.format_pyvista_camera_params(pv_camera)\n",
    "\n",
    "# Create our camera pose\n",
    "poses = [pv_camera[\"c2w\"]]\n",
    "\n",
    "# Create camera arguments for making frustrum\n",
    "camera_kwargs = viz.CAMERA_KWARGS.copy()\n",
    "camera_kwargs.update(\n",
    "    {\n",
    "        \"line_width\": 5,\n",
    "        \"scale\": 0.025,\n",
    "        \"opacity\": 0.9,\n",
    "        \"color\": [0.9, 0.9, 0.9],\n",
    "        \"show_axes\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Select attribute to visualize\n",
    "depth_mesh_kwargs = {\n",
    "    \"scalars\": \"depths\",\n",
    "    \"rgb\": True,\n",
    "}\n",
    "\n",
    "# Show the splat\n",
    "plotter = viz.visualize_splat(\n",
    "    pv_mesh,\n",
    "    poses,\n",
    "    mesh_kwargs=depth_mesh_kwargs,\n",
    "    viz_kwargs=viz.VIZ_KWARGS,\n",
    "    camera_kwargs=camera_kwargs,\n",
    ")\n",
    "\n",
    "# Screenshot and plot as image\n",
    "mesh_image = plotter.screenshot(\n",
    "    window_size=(3000, 3000),\n",
    "    return_img=True,\n",
    ")\n",
    "\n",
    "mesh_image = np.array(mesh_image)\n",
    "plt.imshow(mesh_image)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f6c67d",
   "metadata": {},
   "source": [
    "### Map tracks between spaces\n",
    "\n",
    "Start by loading the tracks as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a297ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the top 5 track IDs\n",
    "n_agents = 20\n",
    "n_min_frames = 150\n",
    "mesh_bounds = 375  # Y coordinate to consider points off the mesh\n",
    "std_threshold = 2  # Filter tracks outside of this many stds of the moving average\n",
    "\n",
    "# Get track counts per ID\n",
    "track_counts = df_tracks.groupby(\"track_id\").size()\n",
    "track_ids = track_counts[track_counts > n_min_frames].index[:n_agents]\n",
    "\n",
    "# Create a subset of the tracks\n",
    "df_subset_tracks = df_tracks[df_tracks[\"track_id\"].isin(track_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a47c39e",
   "metadata": {},
   "source": [
    "Get image coordinates from the bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bca1e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps the bounding box to image coordinates (u, v) formatting\n",
    "uv_coords = df_subset_tracks.apply(\n",
    "    lambda x: reprojection.bbox_to_coords(\n",
    "        x[[\"x1\", \"y1\", \"x2\", \"y2\"]].values.astype(float), method=\"bottom_center\"\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "uv_coords = np.stack(uv_coords)\n",
    "\n",
    "# Now add to the dataframe\n",
    "df_subset_tracks.loc[:, [\"u\", \"v\"]] = uv_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d5eda0",
   "metadata": {},
   "source": [
    "Now put those coordinates in 3D and filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2493f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_tracks = []\n",
    "\n",
    "for track_id, df_id in tqdm(df_subset_tracks.groupby(\"track_id\")):\n",
    "    # Remove points off the mesh\n",
    "    mesh_filter = df_id[\"y2\"] > mesh_bounds\n",
    "    df_id = df_id.loc[mesh_filter]\n",
    "\n",
    "    if df_id.empty:\n",
    "        continue\n",
    "    df_id = df_id.reset_index(drop=True)  # Reset the index for our mapping\n",
    "    df_id = df_id.sort_values(\"frame\")  # Sort by frame number within track\n",
    "\n",
    "    # Filter outliers and smooth tracks\n",
    "    filtered_coords = reprojection.filter_coords(df_id, std_threshold=2)\n",
    "    smoothed_coords = reprojection.smooth_coords(filtered_coords)\n",
    "\n",
    "    # Update original dataframe\n",
    "    df_id.loc[df_id.index, [\"u\", \"v\"]] = smoothed_coords.values\n",
    "    uv_coords = df_id.loc[:, [\"u\", \"v\"]].values\n",
    "\n",
    "    # Apply filtering and smoothing\n",
    "\n",
    "    # TLB need to add size in here\n",
    "    world_points = camera.project_to_world(uv_coords)\n",
    "\n",
    "    # Filter out points that are not on the mesh\n",
    "    mesh_contact_filter = ~np.isnan(world_points).any(1)\n",
    "    world_points = world_points[mesh_contact_filter]\n",
    "\n",
    "    # Add the points and sizes to the dataframe\n",
    "    mesh_contact_idxs = np.where(mesh_contact_filter)[0]\n",
    "    df_id.loc[mesh_contact_idxs, [\"x\", \"y\", \"z\"]] = world_points\n",
    "\n",
    "    # Add to list of dataframes\n",
    "    projected_tracks.append(df_id)\n",
    "\n",
    "df_projected_tracks = pd.concat(projected_tracks).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05da8aa9",
   "metadata": {},
   "source": [
    "#### Plot over images \n",
    "\n",
    "Plot over the original image, mesh view, and mesh depth 2D images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb26f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the original image used to align the camera\n",
    "sampled_frame_dir = aligned_splat_dir / \"sampled-frames\"\n",
    "sampled_frame_fn = list(sampled_frame_dir.glob(\"*.png\"))[0]\n",
    "image = plt.imread(sampled_frame_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96f7f23",
   "metadata": {},
   "source": [
    "Setup plotting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8decf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot over the original image, mesh view, and mesh depth 2D images\n",
    "cmap = \"rainbow\"\n",
    "track_ids = df_projected_tracks[\"track_id\"].unique()\n",
    "n_tracks = len(track_ids)\n",
    "colormap = plt.cm.get_cmap(cmap)  # Using rainbow for bright, distinct colors\n",
    "colors = [colormap(i) for i in np.linspace(0, 1, n_tracks)]\n",
    "track_colors = dict(zip(track_ids, colors))\n",
    "\n",
    "line_kwargs = {\"linestyle\": \"-\", \"linewidth\": 6, \"label\": None, \"alpha\": 1}\n",
    "\n",
    "# Create track_images directory if it doesn't exist\n",
    "os.makedirs(\"track_images\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f740cdf4",
   "metadata": {},
   "source": [
    "Go through each image and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dd6bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = [camera.image, camera.depth, image]\n",
    "\n",
    "for i, current_image in enumerate(all_images):\n",
    "    # Plot tracks on the image\n",
    "    track_image = viz.plot_tracks_on_image(\n",
    "        df_tracks=df_projected_tracks,\n",
    "        image=current_image,\n",
    "        colors=track_colors,\n",
    "        line_kwargs=line_kwargs,\n",
    "    )\n",
    "\n",
    "    # Save each image with a unique name in track_images folder, using tight layout without borders\n",
    "    track_image.savefig(\n",
    "        f\"track_images/track-image-{i}.png\", bbox_inches=\"tight\", pad_inches=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d09f441",
   "metadata": {},
   "source": [
    "#### Plot tracks in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4877481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the pyvista camera parameters\n",
    "pose = [pv_camera[\"c2w\"]]\n",
    "\n",
    "# Format camera frustrum\n",
    "camera_kwargs = viz.CAMERA_KWARGS.copy()\n",
    "camera_kwargs.update(\n",
    "    {\n",
    "        \"line_width\": 5,\n",
    "        \"scale\": 0.025,\n",
    "        \"opacity\": 0.9,\n",
    "        \"color\": [0.9, 0.9, 0.9],\n",
    "        \"show_axes\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Make a plotter\n",
    "plotter = viz.visualize_splat(\n",
    "    mesh_fn.as_posix(),\n",
    "    pose,\n",
    "    mesh_kwargs=viz.MESH_KWARGS,\n",
    "    viz_kwargs=viz.VIZ_KWARGS,\n",
    "    camera_kwargs=camera_kwargs,\n",
    ")\n",
    "\n",
    "# Add the tracks to the plotter\n",
    "plotter = viz.add_tracks_to_mesh(df_projected_tracks, plotter)\n",
    "\n",
    "# Show the plotter\n",
    "# plotter.show(window_size=(800, 800))\n",
    "\n",
    "mesh_image = plotter.screenshot(\n",
    "    window_size=(800, 800),\n",
    "    return_img=True,\n",
    ")\n",
    "\n",
    "mesh_image = np.array(mesh_image)\n",
    "plt.imshow(mesh_image)\n",
    "plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collab-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
