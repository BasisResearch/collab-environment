{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a20766",
   "metadata": {},
   "source": [
    "# Full Tracker: Download, Process, and Upload Data\n",
    "This notebook demonstrates the full pipeline for handling raw data:\n",
    "1. Download data from a cloud bucket.\n",
    "2. Process the data (e.g., align videos, run detection, and tracking).\n",
    "3. Upload the processed data back to the cloud bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d07572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from Desktop.labeling_data.data_structure.Dima_collab.collab_data.file_utils import expand_path, get_project_root\n",
    "from Desktop.labeling_data.data_structure.Dima_collab.collab_data.gcs_utils import GCSClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d4395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Configuration\n",
    "\n",
    "#doing it with full path because I'm too lazy for actual directory management \n",
    "CREDENTIALS_PATH = \"/Users/inesaitsahalia/Desktop/labeling_data/data_structure/Dima_collab/collab_data/api-keys/collab-data-463313-c340ad86b28e.json\"\n",
    "PROJECT_ID = \"collab-data-463313\"\n",
    "BUCKET_NAME = \"fieldwork_data\"  # Update with your bucket name\n",
    "LOCAL_DOWNLOAD_DIR = Path(\"/path/to/local/download\")  # Update with your local download directory\n",
    "LOCAL_PROCESSED_DIR = Path(\"/path/to/local/processed\")  # Update with your local processed directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fb308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Google Cloud Storage\n",
    "gcs_client = GCSClient(\n",
    "    project_id=PROJECT_ID,\n",
    "    credentials_path=CREDENTIALS_PATH,\n",
    "    )\n",
    "\n",
    "# Verify connection\n",
    "print(\"Available buckets:\", gcs_client.list_buckets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827a25b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Data from Cloud Bucket\n",
    "CLOUD_PREFIX = \"your-cloud-prefix\"  # Update with your cloud prefix\n",
    "LOCAL_DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for blob in gcs_client.glob(f\"{BUCKET_NAME}/{CLOUD_PREFIX}/**\"):\n",
    "    local_path = LOCAL_DOWNLOAD_DIR / Path(blob).name\n",
    "    gcs_client.download_file(blob, str(local_path))\n",
    "\n",
    "print(\"Downloaded files:\", list(LOCAL_DOWNLOAD_DIR.iterdir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b804e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the Data\n",
    "print(\"Processing data...\")\n",
    "for file in LOCAL_DOWNLOAD_DIR.iterdir():\n",
    "    if file.suffix == \".csq\":\n",
    "        print(f\"Converting CSQ thermal file: {file}\")\n",
    "        # Convert CSQ thermal files\n",
    "        converted_file = LOCAL_PROCESSED_DIR / f\"{file.stem}.mp4\"\n",
    "        os.system(f\"python pipeline_code/thermal_processing.py --input {file} --output {converted_file}\")\n",
    "\n",
    "    if file.suffix == \".mp4\":\n",
    "        print(f\"Aligning and processing video: {file}\")\n",
    "        # Step 1: Align videos\n",
    "        aligned_rgb_dir = LOCAL_PROCESSED_DIR / \"aligned_rgb\"\n",
    "        aligned_thm_dir = LOCAL_PROCESSED_DIR / \"aligned_thm\"\n",
    "        aligned_rgb_dir.mkdir(parents=True, exist_ok=True)\n",
    "        aligned_thm_dir.mkdir(parents=True, exist_ok=True)\n",
    "        os.system(f\"python pipeline_code_out_of_the_box/scripts/align_videos_manually.py --rgb_video_path {file} --thermal_video_path {file} --output_dir_rgb {aligned_rgb_dir} --output_dir_thm {aligned_thm_dir} --frame_size 640,480\")\n",
    "\n",
    "        # Step 2: Run detection and tracking\n",
    "        print(f\"Running detection and tracking on: {file}\")\n",
    "        os.system(f\"python pipeline_code/local_model_tracking.py --target_root_dir {LOCAL_PROCESSED_DIR} --session_root_dir {file.stem} --camera_type thermal --camera_number 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146dc8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Processed Data to Cloud Bucket\n",
    "CLOUD_PROCESSED_PREFIX = \"your-cloud-processed-prefix\"  # Update with your processed data prefix\n",
    "for file in LOCAL_PROCESSED_DIR.iterdir():\n",
    "    cloud_path = f\"{BUCKET_NAME}/{CLOUD_PROCESSED_PREFIX}/{file.name}\"\n",
    "    gcs_client.upload_file(str(file), cloud_path)\n",
    "\n",
    "print(\"Uploaded processed files:\", list(LOCAL_PROCESSED_DIR.iterdir()))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
