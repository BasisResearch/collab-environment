{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a20766",
   "metadata": {},
   "source": [
    "# Full Tracker: Download, Process, and Upload Data\n",
    "This notebook demonstrates the full pipeline for handling raw data:\n",
    "1. Download data from a cloud bucket.\n",
    "2. Process the data (e.g., align videos, run detection, and tracking).\n",
    "3. Upload the processed data back to the cloud bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d07572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Dict, Tuple\n",
    "\n",
    "# Reload helper for dev work\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# Import Custom Scripts\n",
    "from scripts.thermal_processing import process_directory, validate_session_structure\n",
    "from scripts.align_videos_manually import align_videos, step1_crop_and_prepare, step2_spatial_alignment, save_warped_video\n",
    "from scripts.local_model_tracking import run_tracking, overlay_tracks_on_video, visualize_detections_from_video\n",
    "import subprocess\n",
    "\n",
    "# from Desktop.labeling_data.data_structure.Dima_collab.collab_data.file_utils import expand_path, get_project_root\n",
    "# from Desktop.labeling_data.data_structure.Dima_collab.collab_data.gcs_utils import GCSClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d4395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Configuration\n",
    "\n",
    "#doing it with full path because I'm too lazy for actual directory management \n",
    "CREDENTIALS_PATH = \"/Users/inesaitsahalia/Desktop/labeling_data/data_structure/Dima_collab/collab_data/api-keys/collab-data-463313-c340ad86b28e.json\"\n",
    "PROJECT_ID = \"collab-data-463313\"\n",
    "BUCKET_NAME = \"fieldwork_data\"  # Update with your bucket name\n",
    "LOCAL_DOWNLOAD_DIR = Path(\"/path/to/local/download\")  # Update with your local download directory\n",
    "LOCAL_PROCESSED_DIR = Path(\"/path/to/local/processed\")  # Update with your local processed directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fb308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Google Cloud Storage\n",
    "gcs_client = GCSClient(\n",
    "    project_id=PROJECT_ID,\n",
    "    credentials_path=CREDENTIALS_PATH,\n",
    "    )\n",
    "\n",
    "# Verify connection\n",
    "print(\"Available buckets:\", gcs_client.list_buckets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827a25b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Data from Cloud Bucket\n",
    "CLOUD_PREFIX = \"your-cloud-prefix\"  # Update with your cloud prefix\n",
    "LOCAL_DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for blob in gcs_client.glob(f\"{BUCKET_NAME}/{CLOUD_PREFIX}/**\"):\n",
    "    local_path = LOCAL_DOWNLOAD_DIR / Path(blob).name\n",
    "    gcs_client.download_file(blob, str(local_path))\n",
    "\n",
    "print(\"Downloaded files:\", list(LOCAL_DOWNLOAD_DIR.iterdir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b804e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the Data\n",
    "print(\"Processing data...\")\n",
    "\n",
    "# Validate session structure\n",
    "print(\"Validating session structure...\")\n",
    "validate_session_structure(LOCAL_DOWNLOAD_DIR)\n",
    "\n",
    "#thermal files processing\n",
    "print(\"Processing thermal files...\")\n",
    "process_directory(folder_path=LOCAL_DOWNLOAD_DIR, out_path=LOCAL_DOWNLOAD_DIR, color='magma', preview=True, max_frames=None, fps=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd97256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default parameters for alignment\n",
    "\n",
    "frame_size = (640, 480)  # Default frame size\n",
    "max_frames = 10  # Process all frames by default\n",
    "warp_to = \"rgb\"  # Default warp to rgb, thermal is changing, not rgb\n",
    "rotation_angle = 0.0  # Default rotation angle\n",
    "skip_homography = False  # Default to not skip homography\n",
    "skip_translation = True  # Default to skip translation\n",
    "camera_numbers = [1, 2]  \n",
    "\n",
    "  \n",
    "for camera in camera_numbers:\n",
    "    print(f\"Processing camera {camera}...\")\n",
    "    \n",
    "    # Dynamically find the RGB and thermal MP4 files\n",
    "    rgb_dir = LOCAL_DOWNLOAD_DIR / f\"rgb_{camera}\"\n",
    "    thermal_dir = LOCAL_DOWNLOAD_DIR / f\"thermal_{camera}\"\n",
    "    \n",
    "    # Find the MP4 file in the RGB directory\n",
    "    rgb_video_files = list(rgb_dir.glob(\"*.MP4\")) + list(rgb_dir.glob(\"*.mp4\"))\n",
    "    print('files in rgb_dir:', rgb_video_files)\n",
    "    if len(rgb_video_files) == 0:\n",
    "        print(f\"No MP4 file found in {rgb_dir}. Skipping camera {camera}.\")\n",
    "        continue\n",
    "    elif len(rgb_video_files) > 1:\n",
    "        print(f\"Multiple MP4 files found in {rgb_dir}. Using the first one.\")\n",
    "    rgb_video_path = rgb_video_files[0]\n",
    "    \n",
    "    # Find the MP4 file in the thermal directory\n",
    "    thermal_video_files = list(thermal_dir.glob(\"*.mp4\")) + list(thermal_dir.glob(\"*.MP4\"))\n",
    "    print('files in thermal_dir:', thermal_video_files)\n",
    "    if len(thermal_video_files) == 0:\n",
    "        print(f\"No MP4 file found in {thermal_dir}. Skipping camera {camera}.\")\n",
    "        continue\n",
    "    elif len(thermal_video_files) > 1:\n",
    "        print(f\"Multiple MP4 files found in {thermal_dir}. Using the first one.\")\n",
    "    thermal_video_path = thermal_video_files[0]\n",
    "    \n",
    "    print(f\"RGB video path: {rgb_video_path}\")\n",
    "    print(f\"Thermal video path: {thermal_video_path}\")\n",
    "\n",
    "    output_dir_rgb = LOCAL_PROCESSED_DIR / 'aligned' / f\"rgb_{camera}\"\n",
    "    output_dir_thm = LOCAL_PROCESSED_DIR / 'aligned' / f\"thermal_{camera}\"\n",
    "    output_dir_rgb.mkdir(parents=True, exist_ok=True)\n",
    "    output_dir_thm.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Align videos\n",
    "    print(f\"Aligning videos for camera {camera}...\")\n",
    "\n",
    "    align_videos(\n",
    "        rgb_video_path,\n",
    "        thermal_video_path,\n",
    "        output_dir_rgb,\n",
    "        output_dir_thm,\n",
    "        frame_size=frame_size,\n",
    "        max_frames=max_frames,\n",
    "        warp_to=warp_to,\n",
    "        rotation_angle=rotation_angle,\n",
    "        skip_homography=skip_homography,\n",
    "        skip_translation=skip_translation,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fb42ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection and tracking\n",
    "print(\"Running detection and tracking...\")\n",
    "for camera in camera_numbers:\n",
    "    print(f\"Running detection and tracking on: thermal_{camera}\")\n",
    "    \n",
    "    # Define paths for the thermal video and model inference\n",
    "    thermal_video_path = LOCAL_PROCESSED_DIR / 'aligned' / f\"thermal_{camera}\" / f\"warped_thermal_{camera}.mp4\"\n",
    "    if not thermal_video_path.exists():\n",
    "        print(f\"Thermal video not found for camera {camera}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Run local_model_inference script\n",
    "    print(f\"Running object detection on: {thermal_video_path}\")\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            [\n",
    "                \"python\",\n",
    "                \"scripts/local_model_inference.py\",\n",
    "                \"--vid_name\", thermal_video_path.name,\n",
    "                \"--root_dir\", str(thermal_video_path.parent),\n",
    "                \"--model_weights\", \"scripts/model/weights.pt\"\n",
    "            ],\n",
    "            check=True\n",
    "        )\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error during object detection for camera {camera}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Run tracking\n",
    "    print(f\"Running tracking on: thermal_{camera}\")\n",
    "    run_tracking(LOCAL_PROCESSED_DIR, \"thermal\", camera)\n",
    "\n",
    "    tracked_csv = LOCAL_PROCESSED_DIR / 'aligned' / f\"thermal_{camera}\" / f'thermal_{camera}_tracks.csv'\n",
    "    if not tracked_csv.exists():\n",
    "        print(f\"Tracking CSV not found for camera {camera}. Skipping visualization.\")\n",
    "        continue\n",
    "\n",
    "    #visualization\n",
    "    visualize_detections_from_video(\n",
    "        csv_path=tracked_csv,\n",
    "        video_path=thermal_video_path,\n",
    "        output_video_path=LOCAL_PROCESSED_DIR / 'aligned' / f\"thermal_{camera}\" / f\"visualized_thermal_{camera}.mp4\"\n",
    "    )\n",
    "    print(f\"Visualizing tracks for rgb camera {camera}...\")\n",
    "    overlay_tracks_on_video(\n",
    "        csv_path=tracked_csv,\n",
    "        frame_dir=LOCAL_PROCESSED_DIR / 'aligned' / f\"rgb_{camera}\"/'annotated_frames',\n",
    "        output_video=LOCAL_PROCESSED_DIR / 'aligned' / f\"rgb_{camera}\" / f\"overlayed_tracks_{camera}.mp4\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146dc8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Processed Data to Cloud Bucket\n",
    "CLOUD_PROCESSED_PREFIX = \"your-cloud-processed-prefix\"  # Update with your processed data prefix\n",
    "for file in LOCAL_PROCESSED_DIR.iterdir():\n",
    "    cloud_path = f\"{BUCKET_NAME}/{CLOUD_PROCESSED_PREFIX}/{file.name}\"\n",
    "    gcs_client.upload_file(str(file), cloud_path)\n",
    "\n",
    "print(\"Uploaded processed files:\", list(LOCAL_PROCESSED_DIR.iterdir()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
